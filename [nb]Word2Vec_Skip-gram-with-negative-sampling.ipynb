{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3c1a871-8c59-4904-8ae3-c6c6735f8604",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install torch torchtext==0.17.0 torchdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73a1c781-4e0c-4db3-a1f5-feec1afd5884",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch version:  2.2.0\n",
      "numpy version:  1.25.2\n",
      "nltk version: 3.9.1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "\n",
    "from dataclasses import dataclass, field\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "#nltk.download('punkt')\n",
    "#nltk.download('punkt_tab')\n",
    "\n",
    "from collections import Counter, OrderedDict\n",
    "from typing import Dict, List, Optional, Union\n",
    "from time import monotonic \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print('torch version: ', torch.__version__)\n",
    "print('numpy version: ', np.__version__)\n",
    "print('nltk version:', nltk.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eabe465f-f711-4dc8-993f-e6d25fdb98c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/Users/susan/work/datasets'\n",
    "file = os.path.join(data_dir, \"wiki.train.tokens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28d03b2c-df77-4fb8-a339-973f9e1c3270",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_text(filepath, max_tokens=100000):\n",
    "    with open(filepath, 'r', encoding='utf-8') as f:\n",
    "        text = f.read()\n",
    "    tokens = text.split()\n",
    "    text = \" \".join(tokens[:max_tokens])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "feb7fb0a-2c66-4925-8f8a-e16a11dc34e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded text with 5000 tokens.\n"
     ]
    }
   ],
   "source": [
    "text = load_text(file, max_tokens=5000)\n",
    "print(\"Loaded text with\", len(text.split()), \"tokens.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6abcbe32-16de-43ba-b0de-31e54853d6b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['= Valkyria Chronicles III = Senjō no Valkyria 3 : <unk> Chronicles ( Japanese : 戦場のヴァルキュリア3 , lit .',\n",
       " 'Valkyria of the Battlefield 3 ) , commonly referred to as Valkyria Chronicles III outside Japan , is a tactical role @-@ playing video game developed by Sega and Media.Vision for the PlayStation Portable .']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = sent_tokenize(text)\n",
    "split_sents= [s.lower().split() for s in sentences]\n",
    "sentences[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a991747-55e4-4ebc-93ca-7af6005ae885",
   "metadata": {},
   "outputs": [],
   "source": [
    "_debug_ = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "413277c9-9821-44ab-a123-70a8918c7419",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Params:\n",
    "\n",
    "    # skipgram parameters\n",
    "    dim_embedding = 300\n",
    "    max_norm_embedding = None\n",
    "    min_freq = 1 #50    \n",
    "    threshold = 1.0e-2 # 1.0e-5 subsampling threshold\n",
    "    window_size = 4 # context window one-side length\n",
    "    n_neg_samples = 5 \n",
    "    neg_exponent = 0.75\n",
    "    discarded = \"<>\" # special characters or below threshold frequency\n",
    "    tokenizer = 'basic_english'\n",
    "    \n",
    "    # training parameters\n",
    "    batch_size : int = 10\n",
    "    criterion = None\n",
    "    shuffle = True\n",
    "    learning_rate = 5e-4\n",
    "    n_epochs = 50\n",
    "    train_steps = 1\n",
    "    val_steps = 1\n",
    "    checkpoint_frequency = 1\n",
    "\n",
    "    model_name = 'SkipGram'\n",
    "    model_dir = \"weights/{}\".format(model_name)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "78b46fba-9f0c-4d50-bed8-65dbca2fb725",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TokenMap:\n",
    "    def __init__(self, list_tokens, discarded):\n",
    "        self.by_token = {token:(index, freq) for index, (token,freq) in enumerate(list_tokens)}\n",
    "        self.by_index = {index:(token, freq) for index, (token,freq) in enumerate(list_tokens)}\n",
    "        self.total_tokens = np.nansum([freq for _, (token,freq) in enumerate(list_tokens)], dtype=int)\n",
    "        self.dim_vocab = len(self.by_token)\n",
    "        self.discard_id = self.by_token.get(discarded[0])[0]\n",
    "        discarded[0] \n",
    "        self.discarded = discarded[0]\n",
    "\n",
    "    def get_index(self, word: Union[str, List]):\n",
    "        if isinstance(word, str):\n",
    "            if word in self.by_token:\n",
    "                return self.by_token.get(word)[0]\n",
    "            else:\n",
    "                return self.by_token.get(self.discarded)[0]\n",
    "        elif isinstance(word, list):\n",
    "            ans = []\n",
    "            for w in word:\n",
    "                if w in self.by_token:\n",
    "                    ans.append(self.by_token.get(w)[0])\n",
    "                else:\n",
    "                    ans.append(self.by_token.get(self.discarded)[0])\n",
    "            return ans\n",
    "        else:\n",
    "            raise ValueError(f\"Word {word} should be a string or a list of strings.\")\n",
    "\n",
    "    \n",
    "    def get_token(self, index: Union[int, List]):\n",
    "        if isinstance(index, (int, np.int64)):\n",
    "            if index in self.by_index:\n",
    "                return self.by_index.get(index)[0]\n",
    "            else:\n",
    "                raise ValueError(f\"Index {index} not in valid range\")\n",
    "        elif isinstance(index, list):\n",
    "            ans = []\n",
    "            for j in index:\n",
    "                if j in self.by_token:\n",
    "                    ans.append(self.by_index.get(j)[0])\n",
    "                else:\n",
    "                    raise ValueError(f\"Index {j} not in valid range.\")\n",
    "            return ans    \n",
    "    \n",
    "\n",
    "    def get_frequency(self, word: Union[str, List]):\n",
    "        if isinstance(word, str):\n",
    "            if word in self.by_token:\n",
    "                return self.by_token.get(word)[1]\n",
    "            else:\n",
    "                return self.by_token.get(self.discarded)[1]\n",
    "        elif isinstance(word, list):\n",
    "            ans = []\n",
    "            for w in word:\n",
    "                if w in self.by_token:\n",
    "                    ans.append(self.by_token.get(w)[1])\n",
    "                else:\n",
    "                    ans.append(self.by_token.get(self.discarded)[1])\n",
    "            return ans\n",
    "        else:\n",
    "            raise ValueError(f\"Word {word} should be a string or a list of strings.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc742b11-9ab6-4925-bcc4-6a7d3d1b2f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tokenmap(iter, params : Params, \n",
    "                 max_tokens: Optional[int] = None):\n",
    "   \n",
    "    def filter_tokens(iter_, tokenizer_):\n",
    "        r = re.compile('[a-z1-9]')\n",
    "        for t in iter_:\n",
    "            res = tokenizer_(t)\n",
    "            res = list(filter(r.match, res))\n",
    "            yield res\n",
    "    \n",
    "    tokenizer = get_tokenizer(params.tokenizer)\n",
    "    counter = Counter()\n",
    "    for token_ in filter_tokens(iter, tokenizer):\n",
    "        counter.update(token_)\n",
    "\n",
    "    freq_tuple = sorted(counter.items(), key=lambda x: (-x[1], x[0]))\n",
    "    freq_dict = OrderedDict(freq_tuple)\n",
    "\n",
    "    tokens = []\n",
    "    for token, freq in freq_dict.items():\n",
    "        if freq >= params.min_freq:\n",
    "            tokens.append((token, freq))\n",
    "\n",
    "    discarded = (params.discarded, np.nan)\n",
    "    tokens.append(discarded)\n",
    "\n",
    "    return TokenMap(tokens, discarded)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "57e84478-3254-4775-8a45-e8344336d78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchTool:\n",
    "    def __init__(self, tokenmap: TokenMap, params: Params):\n",
    "        self.map = tokenmap\n",
    "        self.params = params\n",
    "        self.tokenizer = get_tokenizer(params.tokenizer)   \n",
    "        self.discard_probs = self.get_discard_probs()\n",
    "\n",
    "    def frequency_from_percentile(self, percentile= 90):\n",
    "        freq_list = []\n",
    "        for _, (_, freq) in self.map.by_token.items():\n",
    "            if freq == freq:\n",
    "                freq_list.append(freq/self.map.total_tokens)\n",
    "            \n",
    "        return np.percentile(freq_list, percentile)\n",
    "\n",
    "    def get_discard_probs(self):\n",
    "        discard_probs = {}\n",
    "        for _, (word, freq) in self.map.by_token.items():\n",
    "            prob_raw = 1-np.sqrt(self.params.threshold /(freq/self.map.total_tokens))\n",
    "            prob = max(prob_raw,0)\n",
    "            discard_probs[word] = prob\n",
    "        return discard_probs\n",
    "\n",
    "    def collate_fn(self, batches):\n",
    "        inputs, outputs  = [], []\n",
    "        discard_id = self.map.discard_id\n",
    "        \n",
    "        for sentence in batches:\n",
    "            token_ids = self.map.get_index(self.tokenizer(sentence))\n",
    "\n",
    "            if len(token_ids) <= self.params.window_size * 2:\n",
    "                continue\n",
    "\n",
    "            for id in range(len(token_ids) - self.params.window_size*2):\n",
    "                window = token_ids[id : (id + self.params.window_size * 2 + 1)]\n",
    "                target_id = window.pop(self.params.window_size)\n",
    "                context_ids = window\n",
    "              \n",
    "                p = random.random()\n",
    "                p_discard = self.discard_probs.get(target_id)\n",
    "        \n",
    "                if p_discard >= p or target_id == discard_id:\n",
    "                    continue\n",
    "                \n",
    "                for context_id in context_ids:\n",
    "                    p = random.random()\n",
    "                    p_discard = self.discard_probs.get(context_id)\n",
    "                    if p_discard >= p or context_id == discard_id:\n",
    "                        continue\n",
    "                    else:\n",
    "                        inputs.append(target_id)\n",
    "                        outputs.append(context_id)\n",
    "\n",
    "        torch_input = torch.tensor(inputs, dtype=torch.long)\n",
    "        torch_output = torch.tensor(outputs, dtype=torch.long)\n",
    "\n",
    "        return torch_input, torch_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "19ed62bf-7c13-48db-8e31-5d637a33b0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Word2Vec(nn.Module):\n",
    "    def __init__(self, map: TokenMap, params: Params, neg_sd = 'unigram_exp'):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.map = map\n",
    "        self.params = params\n",
    "        self.target_embedding = nn.Embedding(\n",
    "            self.map.dim_vocab,\n",
    "            params.dim_embedding,\n",
    "            max_norm=params.max_norm_embedding\n",
    "            )\n",
    "        self.context_embedding = nn.Embedding(\n",
    "            self.map.dim_vocab,\n",
    "            params.dim_embedding,\n",
    "            max_norm=params.max_norm_embedding\n",
    "            )\n",
    "        self.neg_sd = neg_sd\n",
    "\n",
    "    def forward_target(self, t):\n",
    "        targets = self.target_embedding(t)\n",
    "        return targets\n",
    "\n",
    "    def forward_context(self, c):\n",
    "        contexts = self.context_embedding(c)\n",
    "        return contexts\n",
    "\n",
    "    def forward_neg_sample(self, batch_size, n):\n",
    "        if self.neg_sd =='uniform':\n",
    "            neg_dist = torch.ones(self.map.dim_vocab)\n",
    "        else: \n",
    "            # default : 'unigram_exp' \n",
    "            neg_dist = self.get_unigram_exp()\n",
    "            \n",
    "        neg_samples = torch.multinomial(neg_dist,\n",
    "                                        batch_size * n,\n",
    "                                        replacement=True)\n",
    "        \n",
    "        neg_samples = neg_samples.to(self.params.device)        \n",
    "        neg_samples = self.context_embedding(neg_samples).view(batch_size, n, self.params.dim_embedding)        \n",
    "        return neg_samples\n",
    "\n",
    "\n",
    "    def get_unigram_exp(self):\n",
    "        f = self.map.by_index.copy()\n",
    "        f.pop(self.map.discard_id)\n",
    "        f = dict(f.values())\n",
    "        freqs = np.array(sorted(f.values(), reverse=True))\n",
    "        unigram_dist = freqs/np.nansum(freqs)\n",
    "        assert self.map.total_tokens == np.nansum(freqs), 'Total number of tokens inconsistent!'\n",
    "        \n",
    "        negdist = torch.from_numpy(unigram_dist**(self.params.neg_exponent)/np.sum(unigram_dist**(self.params.neg_exponent)))\n",
    "        return negdist    \n",
    "        \n",
    "    \n",
    "    def get_embedding_norms(self, embedding_vecs):\n",
    "        norms = embedding_vecs.pow(2).sum(dim=1).sqrt().unsqueeze(0)\n",
    "        return norms\n",
    "    \n",
    "\n",
    "    def find_closest_k_words(self, ttokens, topk):\n",
    "\n",
    "        embedding = self.target_embedding.weight\n",
    "        embedding_norms = self.get_embedding_norms(embedding)\n",
    "        test = self.target_embedding(ttokens)\n",
    "        test_norms = self.get_embedding_norms(test)\n",
    "        test_vecs = self.target_embedding(ttokens)\n",
    "\n",
    "        if __debug__ > 1:\n",
    "            print(embedding.shape)\n",
    "            print(embedding_norms.shape)\n",
    "            print(test.shape)  \n",
    "            print(test_norms.shape)\n",
    "        \n",
    "        similarities = torch.mm(test_vecs/test_norms.t(), embedding.t()/embedding_norms)\n",
    "        topk_dists, topk_ids = similarities.topk(topk)\n",
    "        \n",
    "        print(\"\\n-----------\")  \n",
    "        for i, id in enumerate(ttokens):\n",
    "            print(self.map.get_token(id.item()) + \" || \",end='')\n",
    "            dists = [d.item() for d in topk_dists[i]][1:]\n",
    "            topk_words = [self.map.get_token(k.item()) for k in topk_ids[i]][1:]\n",
    "            for j, (w, sim) in enumerate(zip(topk_words,dists)):\n",
    "                #print(w, sim)\n",
    "                print(f\"{w} ({sim:.3f})\", end=' ')\n",
    "            print('\\n')\n",
    "        print(\"-----------\")        \n",
    "        \n",
    "        return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "61567074-bf56-4de8-9e55-376cb3459c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://arxiv.org/pdf/1310.4546\n",
    "\n",
    "class NegativeSamplingLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, inputs, outputs_pos, outputs_neg):\n",
    "        \n",
    "        b, d = inputs.shape        \n",
    "        inputs = inputs.view(b, d, 1)        \n",
    "        outputs_pos = outputs_pos.view(b, 1, d)\n",
    "        \n",
    "        # true context       \n",
    "        pos_loss = torch.bmm(outputs_pos, inputs).sigmoid().log()\n",
    "        pos_loss = pos_loss.squeeze()\n",
    "        # false context\n",
    "        neg_loss = torch.bmm(outputs_neg.neg(), inputs).sigmoid().log()\n",
    "        neg_loss = neg_loss.squeeze().sum(1)  \n",
    "\n",
    "        return -(pos_loss + neg_loss).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2ca76055-ade0-48ae-907e-54435c8b58ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, model: Word2Vec, params: Params, optimizer,\n",
    "                 train_iter, valid_iter, map: TokenMap, method: BatchTool):\n",
    "        self.model = model\n",
    "        self.params = params\n",
    "        self.optimizer = optimizer\n",
    "        self.map = map\n",
    "        self.train_iter = train_iter\n",
    "        self.valid_iter = valid_iter\n",
    "        self.method = method\n",
    "\n",
    "        self.epoch_train_mins = {}\n",
    "        self.loss = {\"train\": [], \"valid\": []}\n",
    "\n",
    "        # sending all to device\n",
    "        self.model.to(self.params.device)\n",
    "        self.params.criterion.to(self.params.device)\n",
    "        self.test_tokens = None\n",
    "\n",
    "\n",
    "    def train(self):\n",
    "        self.do_test()\n",
    "        for epoch in range(self.params.n_epochs):\n",
    "            # load data\n",
    "            self.train_dataloader = DataLoader(\n",
    "                self.train_iter,\n",
    "                batch_size=self.params.batch_size,\n",
    "                shuffle=False,\n",
    "                collate_fn=self.method.collate_fn\n",
    "            )\n",
    "            self.valid_dataloader = DataLoader(\n",
    "                self.valid_iter,\n",
    "                batch_size=self.params.batch_size,\n",
    "                shuffle=False,\n",
    "                collate_fn=self.method.collate_fn\n",
    "            )\n",
    "            \n",
    "            # train model\n",
    "            st_time = monotonic()\n",
    "            self._train_epoch()\n",
    "            self.epoch_train_mins[epoch] = round((monotonic()-st_time)/60, 1)\n",
    "\n",
    "            # validate model\n",
    "            self._validate_epoch()\n",
    "            print(f\"\"\"Epoch: {epoch+1}/{self.params.n_epochs}\\n\"\"\",\n",
    "            f\"\"\"    Train Loss: {self.loss['train'][-1]:.2}\\n\"\"\",\n",
    "            f\"\"\"    Valid Loss: {self.loss['valid'][-1]:.2}\\n\"\"\",\n",
    "            f\"\"\"    Training Time (mins): {self.epoch_train_mins.get(epoch)}\"\"\"\n",
    "            \"\"\"\\n\"\"\"\n",
    "            )\n",
    "            self.do_test()\n",
    "\n",
    "            if self.params.checkpoint_frequency:\n",
    "                self._save_checkpoint(epoch)\n",
    "    \n",
    "\n",
    "    def _train_epoch(self):\n",
    "        self.model.train()\n",
    "        running_loss = []\n",
    "\n",
    "        for i, batch_data in enumerate(self.train_dataloader, 1):\n",
    "            \n",
    "            inputs, outputs = batch_data[0], batch_data[1]\n",
    "            inputs, outputs = inputs.to(self.params.device), outputs.to(self.params.device)\n",
    "            \n",
    "            targets = self.model.forward_target(inputs)\n",
    "            contexts_pos = self.model.forward_context(outputs)\n",
    "            contexts_neg = self.model.forward_neg_sample(inputs.shape[0], params.n_neg_samples)            \n",
    "            loss = self.params.criterion(targets, contexts_pos, contexts_neg)\n",
    "            \n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "            running_loss.append(loss.item())\n",
    "\n",
    "        epoch_loss = np.mean(running_loss)\n",
    "        self.loss['train'].append(epoch_loss)\n",
    "\n",
    "    def _validate_epoch(self):\n",
    "        self.model.eval()\n",
    "        running_loss = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for i, batch_data in enumerate(self.valid_dataloader, 1):\n",
    "\n",
    "                inputs, outputs = batch_data[0], batch_data[1]\n",
    "                inputs, outputs = inputs.to(self.params.device), outputs.to(self.params.device)\n",
    "            \n",
    "                targets = self.model.forward_target(inputs)\n",
    "                contexts_pos = self.model.forward_context(outputs)\n",
    "                contexts_neg = self.model.forward_neg_sample(inputs.shape[0], params.n_neg_samples)            \n",
    "                loss = self.params.criterion(targets, contexts_pos, contexts_neg)\n",
    "\n",
    "                running_loss.append(loss.item())\n",
    "\n",
    "            epoch_loss = np.mean(running_loss)\n",
    "            self.loss['valid'].append(epoch_loss)\n",
    "\n",
    "    def _save_checkpoint(self, epoch):\n",
    "        \"\"\"Save model checkpoint to `self.model_dir` directory\"\"\"\n",
    "        epoch_num = epoch + 1\n",
    "        if epoch_num % self.params.checkpoint_frequency == 0:\n",
    "            model_path = \"checkpoint_{}.pt\".format(str(epoch_num).zfill(3))\n",
    "            model_path = os.path.join(self.params.model_dir, model_path)\n",
    "            torch.save(self.model, model_path)\n",
    "\n",
    "    def save_model(self):\n",
    "        \"\"\"Save final model to `self.model_dir` directory\"\"\"\n",
    "        model_path = os.path.join(self.params.model_dir, \"model.pt\")\n",
    "        torch.save(self.model, model_path)\n",
    "\n",
    "    def save_loss(self):\n",
    "        \"\"\"Save train/val loss as json file to `self.model_dir` directory\"\"\"\n",
    "        loss_path = os.path.join(self.params.model_dir, \"loss.json\")\n",
    "        with open(loss_path, \"w\") as fp:\n",
    "            json.dump(self.loss, fp)\n",
    "    \n",
    "    def do_test(self, topk: int = 5):\n",
    "        sampling_window=100\n",
    "        test_size = 10\n",
    "        if self.test_tokens != None:\n",
    "            ttokens= self.test_tokens\n",
    "            for w in self.test_tokens:\n",
    "                idw = self.map.get_index(w)\n",
    "                if idw == self.map.discard_id:\n",
    "                    print(f\"Word {w} not in Vocabulary\")\n",
    "            return\n",
    "        else:\n",
    "            ttokens= np.array(random.sample(range(sampling_window), test_size//2)) # high frequency tokens\n",
    "            ttokens=np.append(ttokens,random.sample(range(1000,1000+sampling_window), test_size//2)) #low frequency tokens\n",
    "\n",
    "        ttokens = torch.tensor(ttokens, dtype=torch.long).to(self.params.device)\n",
    "\n",
    "        self.model.find_closest_k_words(ttokens, topk)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "da2928e1-8ffc-4857-b7ac-49163f0398f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = text.lower()\n",
    "it = iter(text.split())\n",
    "params = Params()\n",
    "params.criterion = NegativeSamplingLoss()\n",
    "os.makedirs(params.model_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dbfd2770-eaa3-4a87-abaf-3916c8e76bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmap = build_tokenmap(it, params)\n",
    "batchtool = BatchTool(tmap, params)\n",
    "w2v = Word2Vec(tmap, params)\n",
    "optimizer = torch.optim.Adam(params = w2v.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "11956e1c-a0f3-4dbe-9d41-10af29731dd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------\n",
      "they || large (0.197) at (0.176) research (0.175) governor (0.166) \n",
      "\n",
      "as || extended (0.189) after (0.169) temporary (0.164) apply (0.160) \n",
      "\n",
      "in || summer (0.166) maintaining (0.164) third (0.154) unless (0.152) \n",
      "\n",
      "no || boosts (0.180) platform (0.158) post (0.156) jinxed (0.150) \n",
      "\n",
      "story || underwent (0.200) article (0.181) title (0.172) erase (0.154) \n",
      "\n",
      "plot || two (0.191) unlocked (0.170) arms (0.169) surrendering (0.154) \n",
      "\n",
      "novel || guarantee (0.211) scanned (0.186) weapon (0.173) offenders (0.163) \n",
      "\n",
      "receives || several (0.180) gameplay (0.175) gallia (0.169) precious (0.161) \n",
      "\n",
      "option || inadequate (0.212) form (0.200) them (0.176) linear (0.164) \n",
      "\n",
      "plausible || unit (0.194) did (0.176) antiquities (0.165) united (0.164) \n",
      "\n",
      "-----------\n",
      "Epoch: 1/50\n",
      "     Train Loss: 4.1e+01\n",
      "     Valid Loss: 4.2e+01\n",
      "     Training Time (mins): 0.0\n",
      "\n",
      "\n",
      "-----------\n",
      "governor || 4 (0.182) walker (0.181) they (0.166) 10 (0.165) \n",
      "\n",
      "playstation || composer (0.211) item (0.201) switch (0.187) shortly (0.164) \n",
      "\n",
      "his || depot (0.193) identities (0.190) six (0.163) americans (0.163) \n",
      "\n",
      "team || worked (0.176) kept (0.172) kondō (0.162) deserters (0.148) \n",
      "\n",
      "due || play (0.187) proved (0.177) effort (0.170) found (0.169) \n",
      "\n",
      "occasional || successful (0.213) closure (0.180) thereon (0.159) john (0.157) \n",
      "\n",
      "overturned || post (0.194) demo (0.190) target (0.185) lose (0.179) \n",
      "\n",
      "portraits || museum (0.151) 4 (0.149) taga (0.145) war (0.145) \n",
      "\n",
      "particular || became (0.193) abilities (0.190) subject (0.179) battle (0.164) \n",
      "\n",
      "non || without (0.170) seemingly (0.168) sic (0.165) octagonal (0.162) \n",
      "\n",
      "-----------\n",
      "Epoch: 2/50\n",
      "     Train Loss: 4.1e+01\n",
      "     Valid Loss: 4.2e+01\n",
      "     Training Time (mins): 0.0\n",
      "\n",
      "\n",
      "-----------\n",
      "gallian || class (0.240) full (0.183) thirty (0.169) 1942 (0.152) \n",
      "\n",
      "february || it (0.212) name (0.172) wish (0.171) unless (0.167) \n",
      "\n",
      "no || boosts (0.181) platform (0.157) post (0.156) jinxed (0.150) \n",
      "\n",
      "anime || quality (0.162) kazuki (0.158) highly (0.157) thick (0.155) \n",
      "\n",
      "its || hana (0.193) permanent (0.178) playing (0.169) left (0.163) \n",
      "\n",
      "ohta || progresses (0.179) handled (0.165) handful (0.162) him (0.155) \n",
      "\n",
      "others || response (0.218) wii (0.191) designed (0.171) from (0.166) \n",
      "\n",
      "promote || call (0.171) hounded (0.159) yet (0.158) 8 (0.158) \n",
      "\n",
      "pictures || ramsey (0.179) south (0.175) speech (0.169) assumed (0.166) \n",
      "\n",
      "principle || criticized (0.228) sega (0.224) people (0.170) highly (0.163) \n",
      "\n",
      "-----------\n",
      "Epoch: 3/50\n",
      "     Train Loss: 4e+01\n",
      "     Valid Loss: 4.1e+01\n",
      "     Training Time (mins): 0.0\n",
      "\n",
      "\n",
      "-----------\n",
      "release || of (0.202) newer (0.177) pacing (0.164) initially (0.150) \n",
      "\n",
      "who || reinforcements (0.184) were (0.177) 1894 (0.170) raven (0.162) \n",
      "\n",
      "is || young (0.186) garrison (0.169) united (0.161) raven (0.150) \n",
      "\n",
      "iii || proved (0.184) playable (0.175) price (0.173) gaming (0.155) \n",
      "\n",
      "an || azure (0.172) go (0.161) prove (0.158) content (0.157) \n",
      "\n",
      "protagonists || again (0.194) expressing (0.186) flash (0.165) moves (0.164) \n",
      "\n",
      "president || conway (0.208) unaltered (0.192) gameplay (0.181) removed (0.174) \n",
      "\n",
      "particularly || masonry (0.204) additional (0.171) seeks (0.167) appearances (0.161) \n",
      "\n",
      "plot || two (0.190) unlocked (0.170) arms (0.169) surrendering (0.154) \n",
      "\n",
      "progresses || differing (0.214) getting (0.189) central (0.185) ohta (0.179) \n",
      "\n",
      "-----------\n",
      "Epoch: 4/50\n",
      "     Train Loss: 4e+01\n",
      "     Valid Loss: 4e+01\n",
      "     Training Time (mins): 0.0\n",
      "\n",
      "\n",
      "-----------\n",
      "are || victory (0.210) inadequate (0.210) asking (0.198) expense (0.195) \n",
      "\n",
      "he || safe (0.189) 10 (0.178) begin (0.163) components (0.158) \n",
      "\n",
      "elements || continued (0.183) improved (0.177) perspective (0.170) war (0.159) \n",
      "\n",
      "playstation || composer (0.212) item (0.201) switch (0.186) shortly (0.164) \n",
      "\n",
      "by || topped (0.197) member (0.192) featuring (0.191) independence (0.178) \n",
      "\n",
      "playable || iii (0.174) determine (0.173) game (0.169) allocated (0.166) \n",
      "\n",
      "newly || save (0.200) speech (0.194) destroys (0.182) woman (0.171) \n",
      "\n",
      "prompted || translated (0.182) rumor (0.159) perhaps (0.158) english (0.150) \n",
      "\n",
      "prove || mysterious (0.226) assembled (0.186) an (0.157) single (0.157) \n",
      "\n",
      "nintendo || appearance (0.176) summer (0.173) jinxed (0.172) redeem (0.162) \n",
      "\n",
      "-----------\n",
      "Epoch: 5/50\n",
      "     Train Loss: 3.9e+01\n",
      "     Valid Loss: 4e+01\n",
      "     Training Time (mins): 0.0\n",
      "\n",
      "\n",
      "-----------\n",
      "being || 1894 (0.161) held (0.159) become (0.149) dlc (0.149) \n",
      "\n",
      "main || were (0.183) demand (0.176) works (0.175) found (0.163) \n",
      "\n",
      "it || february (0.213) 4th (0.201) specimen (0.176) supposed (0.168) \n",
      "\n",
      "one || these (0.184) erased (0.174) supreme (0.170) frontier (0.169) \n",
      "\n",
      "missions || 1997 (0.163) permanent (0.152) deserters (0.150) confronts (0.146) \n",
      "\n",
      "outposts || purchase (0.179) where (0.170) orders (0.168) ease (0.166) \n",
      "\n",
      "poor || certain (0.175) second (0.172) did (0.172) anonymous (0.148) \n",
      "\n",
      "purpose || chance (0.188) always (0.187) name (0.183) great (0.167) \n",
      "\n",
      "receives || several (0.181) gameplay (0.176) gallia (0.168) precious (0.162) \n",
      "\n",
      "novel || guarantee (0.210) scanned (0.186) weapon (0.172) offenders (0.163) \n",
      "\n",
      "-----------\n",
      "Epoch: 6/50\n",
      "     Train Loss: 3.9e+01\n",
      "     Valid Loss: 3.9e+01\n",
      "     Training Time (mins): 0.0\n",
      "\n",
      "\n",
      "-----------\n",
      "arkansas || 1861 (0.157) unconfirmed (0.154) world (0.152) forms (0.145) \n",
      "\n",
      "along || coming (0.174) watch (0.163) club (0.158) interview (0.155) \n",
      "\n",
      "such || divorced (0.185) assemble (0.181) review (0.159) determined (0.155) \n",
      "\n",
      "into || battlefield (0.183) hinting (0.178) pleased (0.172) henry (0.165) \n",
      "\n",
      "elements || continued (0.184) improved (0.177) perspective (0.169) war (0.160) \n",
      "\n",
      "peace || consequence (0.180) sung (0.168) simulation (0.165) 422 (0.153) \n",
      "\n",
      "reality || noting (0.171) defects (0.169) when (0.165) yamanobe (0.159) \n",
      "\n",
      "praising || 5 (0.214) takayuki (0.180) closure (0.173) up (0.169) \n",
      "\n",
      "non || without (0.169) seemingly (0.167) sic (0.165) octagonal (0.163) \n",
      "\n",
      "overall || recorded (0.210) carrying (0.202) expel (0.178) criticisms (0.160) \n",
      "\n",
      "-----------\n",
      "Epoch: 7/50\n",
      "     Train Loss: 3.8e+01\n",
      "     Valid Loss: 3.9e+01\n",
      "     Training Time (mins): 0.0\n",
      "\n",
      "\n",
      "-----------\n",
      "story || underwent (0.200) article (0.183) title (0.171) erase (0.157) \n",
      "\n",
      "2011 || famitsu (0.262) told (0.175) redeem (0.171) worked (0.170) \n",
      "\n",
      "into || battlefield (0.183) hinting (0.179) pleased (0.172) henry (0.165) \n",
      "\n",
      "theme || alongside (0.176) individuality (0.157) bass (0.154) quickly (0.154) \n",
      "\n",
      "no || boosts (0.182) platform (0.157) post (0.155) jinxed (0.149) \n",
      "\n",
      "ready || returning (0.160) writers (0.158) incursion (0.156) concept (0.153) \n",
      "\n",
      "precious || either (0.236) control (0.188) sealed (0.177) receives (0.162) \n",
      "\n",
      "permitted || honjou (0.190) club (0.177) classes (0.169) if (0.146) \n",
      "\n",
      "nobuhiro || happens (0.182) fantasy (0.170) besides (0.167) linear (0.165) \n",
      "\n",
      "provisions || focused (0.199) proposed (0.193) extended (0.185) off (0.181) \n",
      "\n",
      "-----------\n",
      "Epoch: 8/50\n",
      "     Train Loss: 3.8e+01\n",
      "     Valid Loss: 3.9e+01\n",
      "     Training Time (mins): 0.0\n",
      "\n",
      "\n",
      "-----------\n",
      "theme || alongside (0.176) individuality (0.157) bass (0.155) quickly (0.154) \n",
      "\n",
      "federal || evidence (0.203) my (0.190) akari (0.186) shinji (0.177) \n",
      "\n",
      "during || volumes (0.171) identities (0.159) themselves (0.158) referred (0.156) \n",
      "\n",
      "a || engine (0.159) militia (0.155) seiko (0.154) forced (0.153) \n",
      "\n",
      "games || none (0.182) g (0.173) consequences (0.166) compose (0.159) \n",
      "\n",
      "perspective || crowe (0.185) met (0.185) native (0.175) elements (0.169) \n",
      "\n",
      "poor || certain (0.174) did (0.172) second (0.171) anonymous (0.148) \n",
      "\n",
      "perhaps || valkyrie (0.184) episodic (0.184) cease (0.169) one (0.163) \n",
      "\n",
      "reality || noting (0.170) defects (0.169) when (0.165) yamanobe (0.159) \n",
      "\n",
      "purpose || chance (0.189) always (0.186) name (0.183) ai (0.167) \n",
      "\n",
      "-----------\n",
      "Epoch: 9/50\n",
      "     Train Loss: 3.7e+01\n",
      "     Valid Loss: 3.9e+01\n",
      "     Training Time (mins): 0.0\n",
      "\n",
      "\n",
      "-----------\n",
      "order || achieve (0.200) records (0.173) conquered (0.171) handful (0.169) \n",
      "\n",
      "to || march (0.163) ryan (0.161) confronts (0.161) continued (0.151) \n",
      "\n",
      "troops || number (0.179) completing (0.158) perform (0.155) convention (0.152) \n",
      "\n",
      "is || young (0.187) garrison (0.169) united (0.160) raven (0.152) \n",
      "\n",
      "than || sung (0.165) conway (0.160) enemies (0.156) protagonists (0.155) \n",
      "\n",
      "pre || appropriated (0.181) great (0.178) according (0.166) forms (0.155) \n",
      "\n",
      "quickly || goes (0.174) extra (0.160) works (0.157) serve (0.154) \n",
      "\n",
      "promote || call (0.169) hounded (0.159) yet (0.158) 8 (0.158) \n",
      "\n",
      "perspective || crowe (0.185) met (0.185) native (0.175) elements (0.169) \n",
      "\n",
      "presence || unofficial (0.198) designs (0.174) required (0.170) grown (0.169) \n",
      "\n",
      "-----------\n",
      "Epoch: 10/50\n",
      "     Train Loss: 3.7e+01\n",
      "     Valid Loss: 3.8e+01\n",
      "     Training Time (mins): 0.0\n",
      "\n",
      "\n",
      "-----------\n",
      "same || part (0.198) azure (0.187) criticized (0.182) featuring (0.180) \n",
      "\n",
      "it || february (0.213) 4th (0.201) specimen (0.176) supposed (0.167) \n",
      "\n",
      "his || depot (0.196) identities (0.188) six (0.164) americans (0.164) \n",
      "\n",
      "development || ammunition (0.217) home (0.201) unique (0.191) telegram (0.180) \n",
      "\n",
      "he || safe (0.189) 10 (0.178) begin (0.164) components (0.158) \n",
      "\n",
      "offenders || told (0.194) simulation (0.185) reassess (0.185) used (0.168) \n",
      "\n",
      "operations || whose (0.167) wire (0.162) decommissioning (0.162) serve (0.160) \n",
      "\n",
      "pictures || ramsey (0.180) south (0.174) speech (0.169) subject (0.166) \n",
      "\n",
      "preview || highly (0.171) 91 (0.155) motto (0.150) titled (0.146) \n",
      "\n",
      "overall || recorded (0.210) carrying (0.201) expel (0.179) criticisms (0.160) \n",
      "\n",
      "-----------\n",
      "Epoch: 11/50\n",
      "     Train Loss: 3.6e+01\n",
      "     Valid Loss: 3.8e+01\n",
      "     Training Time (mins): 0.0\n",
      "\n",
      "\n",
      "-----------\n",
      "their || removal (0.188) fears (0.174) detail (0.166) gameplay (0.164) \n",
      "\n",
      "of || throughout (0.203) release (0.202) settings (0.163) music (0.162) \n",
      "\n",
      "by || topped (0.198) member (0.191) featuring (0.188) independence (0.176) \n",
      "\n",
      "war || with (0.226) player (0.195) names (0.178) field (0.173) \n",
      "\n",
      "squad || received (0.162) convention (0.159) 27 (0.158) wanted (0.151) \n",
      "\n",
      "possible || parallel (0.186) instruments (0.184) part (0.175) telegram (0.169) \n",
      "\n",
      "nine || newer (0.198) escorted (0.189) robert (0.177) always (0.166) \n",
      "\n",
      "protagonists || again (0.194) expressing (0.183) moves (0.165) flash (0.165) \n",
      "\n",
      "outposts || purchase (0.179) where (0.169) orders (0.168) took (0.165) \n",
      "\n",
      "none || face (0.210) effort (0.205) games (0.183) expose (0.171) \n",
      "\n",
      "-----------\n",
      "Epoch: 12/50\n",
      "     Train Loss: 3.6e+01\n",
      "     Valid Loss: 3.8e+01\n",
      "     Training Time (mins): 0.0\n",
      "\n",
      "\n",
      "-----------\n",
      "be || fears (0.206) armed (0.202) table (0.182) assembled (0.160) \n",
      "\n",
      "rock || totten (0.174) control (0.172) blurring (0.158) recalled (0.157) \n",
      "\n",
      "at || grant (0.215) response (0.208) they (0.176) very (0.171) \n",
      "\n",
      "release || of (0.202) newer (0.177) pacing (0.166) initially (0.148) \n",
      "\n",
      "battle || found (0.176) skills (0.170) destroyed (0.169) seven (0.166) \n",
      "\n",
      "polygon || tactical (0.169) left (0.161) distributed (0.159) unique (0.159) \n",
      "\n",
      "property || calamity (0.182) person (0.161) anonymous (0.151) portable (0.149) \n",
      "\n",
      "protagonists || again (0.194) expressing (0.183) moves (0.165) flash (0.164) \n",
      "\n",
      "principle || criticized (0.228) sega (0.224) people (0.170) highly (0.164) \n",
      "\n",
      "racetrack || problems (0.192) blue (0.181) club (0.168) staff (0.158) \n",
      "\n",
      "-----------\n",
      "Epoch: 13/50\n",
      "     Train Loss: 3.6e+01\n",
      "     Valid Loss: 3.8e+01\n",
      "     Training Time (mins): 0.0\n",
      "\n",
      "\n",
      "-----------\n",
      "missions || 1997 (0.162) permanent (0.152) deserters (0.148) either (0.145) \n",
      "\n",
      "by || topped (0.199) member (0.190) featuring (0.187) independence (0.176) \n",
      "\n",
      "are || inadequate (0.211) victory (0.211) expense (0.195) asking (0.195) \n",
      "\n",
      "due || play (0.186) proved (0.175) effort (0.175) found (0.170) \n",
      "\n",
      "s || g (0.209) riela (0.180) exterior (0.171) ultimate (0.167) \n",
      "\n",
      "ohta || progresses (0.180) handled (0.167) handful (0.163) him (0.157) \n",
      "\n",
      "purchase || limited (0.192) outposts (0.179) guitar (0.177) antiquities (0.167) \n",
      "\n",
      "pacific || recently (0.236) turns (0.176) thick (0.159) whose (0.158) \n",
      "\n",
      "psp || these (0.216) according (0.197) potentials (0.164) towards (0.159) \n",
      "\n",
      "particular || became (0.192) abilities (0.188) subject (0.178) battle (0.165) \n",
      "\n",
      "-----------\n",
      "Epoch: 14/50\n",
      "     Train Loss: 3.5e+01\n",
      "     Valid Loss: 3.7e+01\n",
      "     Training Time (mins): 0.0\n",
      "\n",
      "\n",
      "-----------\n",
      "to || march (0.162) ryan (0.160) confronts (0.159) continued (0.152) \n",
      "\n",
      "by || topped (0.199) member (0.190) featuring (0.187) independence (0.176) \n",
      "\n",
      "gallian || class (0.241) full (0.185) thirty (0.170) 1942 (0.153) \n",
      "\n",
      "through || forgiving (0.203) comic (0.161) macarthur (0.161) known (0.161) \n",
      "\n",
      "ii || revealed (0.216) replayed (0.179) eisenbeis (0.169) perhaps (0.163) \n",
      "\n",
      "particularly || masonry (0.204) additional (0.173) seeks (0.168) appearances (0.161) \n",
      "\n",
      "recalled || franchise (0.211) exemplified (0.202) gaming (0.199) wanting (0.194) \n",
      "\n",
      "problem || sentiment (0.160) officer (0.157) nation (0.154) maoh (0.149) \n",
      "\n",
      "panels || smith (0.175) b (0.172) approach (0.167) turn (0.166) \n",
      "\n",
      "preview || highly (0.171) 91 (0.155) motto (0.149) titled (0.146) \n",
      "\n",
      "-----------\n",
      "Epoch: 15/50\n",
      "     Train Loss: 3.5e+01\n",
      "     Valid Loss: 3.7e+01\n",
      "     Training Time (mins): 0.0\n",
      "\n",
      "\n",
      "-----------\n",
      "squad || received (0.163) convention (0.158) 27 (0.158) fate (0.151) \n",
      "\n",
      "order || achieve (0.201) records (0.172) conquered (0.171) handful (0.169) \n",
      "\n",
      "as || extended (0.193) composed (0.169) after (0.166) apply (0.163) \n",
      "\n",
      "been || activate (0.157) vision (0.156) seiko (0.155) instead (0.154) \n",
      "\n",
      "no || boosts (0.182) platform (0.155) post (0.153) jinxed (0.148) \n",
      "\n",
      "problem || sentiment (0.161) officer (0.157) nation (0.155) maoh (0.149) \n",
      "\n",
      "ramsey || january (0.190) pictures (0.182) kazuki (0.166) stripped (0.166) \n",
      "\n",
      "particularly || masonry (0.204) additional (0.173) seeks (0.169) appearances (0.162) \n",
      "\n",
      "perhaps || valkyrie (0.184) episodic (0.183) cease (0.169) one (0.163) \n",
      "\n",
      "pre || appropriated (0.181) great (0.178) according (0.166) theme (0.155) \n",
      "\n",
      "-----------\n",
      "Epoch: 16/50\n",
      "     Train Loss: 3.4e+01\n",
      "     Valid Loss: 3.7e+01\n",
      "     Training Time (mins): 0.0\n",
      "\n",
      "\n",
      "-----------\n",
      "their || removal (0.187) fears (0.175) gameplay (0.167) detail (0.167) \n",
      "\n",
      "rock || totten (0.173) control (0.173) blurring (0.157) recalled (0.156) \n",
      "\n",
      "on || creating (0.189) authorized (0.188) critics (0.149) visuals (0.144) \n",
      "\n",
      "along || coming (0.177) watch (0.160) club (0.156) interview (0.155) \n",
      "\n",
      "little || difficulty (0.184) 27 (0.181) face (0.176) decommissioning (0.172) \n",
      "\n",
      "now || chance (0.225) create (0.191) unofficial (0.175) returned (0.170) \n",
      "\n",
      "panels || smith (0.176) b (0.172) approach (0.168) responsibility (0.166) \n",
      "\n",
      "pictures || ramsey (0.182) south (0.174) speech (0.169) subject (0.166) \n",
      "\n",
      "others || response (0.221) wii (0.191) designed (0.171) from (0.166) \n",
      "\n",
      "point || 13 (0.190) demo (0.184) although (0.179) hiroshi (0.171) \n",
      "\n",
      "-----------\n",
      "Epoch: 17/50\n",
      "     Train Loss: 3.4e+01\n",
      "     Valid Loss: 3.6e+01\n",
      "     Training Time (mins): 0.0\n",
      "\n",
      "\n",
      "-----------\n",
      "his || depot (0.198) identities (0.187) six (0.165) americans (0.165) \n",
      "\n",
      "can || needed (0.175) seeks (0.162) heroines (0.155) particular (0.154) \n",
      "\n",
      "through || forgiving (0.202) macarthur (0.163) known (0.162) comic (0.162) \n",
      "\n",
      "not || need (0.177) affected (0.168) patch (0.165) half (0.164) \n",
      "\n",
      "along || coming (0.178) watch (0.159) club (0.156) interview (0.155) \n",
      "\n",
      "recently || pacific (0.236) nintendo (0.148) delivery (0.146) although (0.143) \n",
      "\n",
      "novel || guarantee (0.209) scanned (0.187) weapon (0.171) offenders (0.163) \n",
      "\n",
      "offered || reveal (0.190) years (0.184) versions (0.164) armed (0.162) \n",
      "\n",
      "procession || essential (0.198) media (0.186) table (0.182) sense (0.176) \n",
      "\n",
      "now || chance (0.225) create (0.192) unofficial (0.175) returned (0.169) \n",
      "\n",
      "-----------\n",
      "Epoch: 18/50\n",
      "     Train Loss: 3.4e+01\n",
      "     Valid Loss: 3.6e+01\n",
      "     Training Time (mins): 0.0\n",
      "\n",
      "\n",
      "-----------\n",
      "character || experience (0.182) site (0.171) saku (0.169) outskirts (0.159) \n",
      "\n",
      "squad || received (0.165) 27 (0.158) convention (0.158) fate (0.151) \n",
      "\n",
      "february || it (0.213) wish (0.173) name (0.172) unless (0.168) \n",
      "\n",
      "been || activate (0.158) vision (0.156) instead (0.154) seiko (0.154) \n",
      "\n",
      "missions || 1997 (0.162) permanent (0.151) deserters (0.147) either (0.146) \n",
      "\n",
      "recently || pacific (0.236) nintendo (0.148) delivery (0.146) although (0.143) \n",
      "\n",
      "possible || parallel (0.187) instruments (0.184) part (0.175) telegram (0.169) \n",
      "\n",
      "prompted || translated (0.181) rumor (0.159) perhaps (0.158) english (0.150) \n",
      "\n",
      "price || house (0.187) however (0.187) iii (0.169) simple (0.167) \n",
      "\n",
      "nintendo || appearance (0.176) summer (0.176) jinxed (0.174) redeem (0.163) \n",
      "\n",
      "-----------\n",
      "Epoch: 19/50\n",
      "     Train Loss: 3.3e+01\n",
      "     Valid Loss: 3.6e+01\n",
      "     Training Time (mins): 0.0\n",
      "\n",
      "\n",
      "-----------\n",
      "game || components (0.231) western (0.181) playable (0.172) works (0.172) \n",
      "\n",
      "first || played (0.202) become (0.200) garrison (0.151) essentially (0.151) \n",
      "\n",
      "previous || review (0.183) apply (0.173) large (0.160) despite (0.158) \n",
      "\n",
      "battle || found (0.175) skills (0.172) seven (0.170) destroyed (0.167) \n",
      "\n",
      "anime || quality (0.162) highly (0.161) kazuki (0.160) table (0.154) \n",
      "\n",
      "plot || two (0.188) unlocked (0.170) arms (0.169) surrendering (0.154) \n",
      "\n",
      "particularly || masonry (0.203) additional (0.174) seeks (0.168) appearances (0.162) \n",
      "\n",
      "pitted || used (0.161) begin (0.160) lower (0.155) names (0.150) \n",
      "\n",
      "prevent || guitar (0.159) civil (0.158) unaltered (0.147) vehicles (0.143) \n",
      "\n",
      "quality || hana (0.188) occurs (0.178) did (0.174) depleting (0.163) \n",
      "\n",
      "-----------\n",
      "Epoch: 20/50\n",
      "     Train Loss: 3.3e+01\n",
      "     Valid Loss: 3.7e+01\n",
      "     Training Time (mins): 0.0\n",
      "\n",
      "\n",
      "-----------\n",
      "characters || art (0.179) secession (0.169) owned (0.168) played (0.162) \n",
      "\n",
      "3 || produced (0.207) effort (0.168) destroyed (0.164) provided (0.162) \n",
      "\n",
      "being || held (0.162) 1894 (0.159) become (0.152) translated (0.149) \n",
      "\n",
      "had || ammunition (0.193) save (0.152) telling (0.148) told (0.148) \n",
      "\n",
      "army || atonality (0.200) flux (0.171) gradually (0.167) vision (0.157) \n",
      "\n",
      "option || inadequate (0.211) form (0.196) them (0.176) linear (0.167) \n",
      "\n",
      "provisions || focused (0.197) proposed (0.196) extended (0.182) off (0.177) \n",
      "\n",
      "quality || hana (0.188) occurs (0.178) did (0.174) depleting (0.163) \n",
      "\n",
      "protagonists || again (0.194) expressing (0.181) moves (0.166) flash (0.162) \n",
      "\n",
      "plot || two (0.188) unlocked (0.169) arms (0.169) surrendering (0.154) \n",
      "\n",
      "-----------\n",
      "Epoch: 21/50\n",
      "     Train Loss: 3.3e+01\n",
      "     Valid Loss: 3.6e+01\n",
      "     Training Time (mins): 0.0\n",
      "\n",
      "\n",
      "-----------\n",
      "little || difficulty (0.184) 27 (0.180) face (0.175) decommissioning (0.173) \n",
      "\n",
      "arsenal || suffers (0.216) troopers (0.191) criminals (0.179) link (0.174) \n",
      "\n",
      "theme || alongside (0.174) bass (0.157) individuality (0.155) pre (0.155) \n",
      "\n",
      "battlefield || dlc (0.197) book (0.187) into (0.182) cutscenes (0.170) \n",
      "\n",
      "each || visual (0.185) interpose (0.166) written (0.162) number (0.153) \n",
      "\n",
      "owing || shared (0.162) majority (0.139) adjustments (0.137) distress (0.137) \n",
      "\n",
      "octagonal || wire (0.166) non (0.162) officers (0.156) listed (0.154) \n",
      "\n",
      "procession || essential (0.198) media (0.186) table (0.182) sense (0.177) \n",
      "\n",
      "offenders || told (0.195) reassess (0.185) simulation (0.184) used (0.169) \n",
      "\n",
      "property || calamity (0.183) person (0.161) anonymous (0.151) portable (0.149) \n",
      "\n",
      "-----------\n",
      "Epoch: 22/50\n",
      "     Train Loss: 3.2e+01\n",
      "     Valid Loss: 3.6e+01\n",
      "     Training Time (mins): 0.0\n",
      "\n",
      "\n",
      "-----------\n",
      "development || ammunition (0.216) home (0.199) unique (0.194) telegram (0.181) \n",
      "\n",
      "games || none (0.185) g (0.170) consequences (0.164) regular (0.163) \n",
      "\n",
      "their || removal (0.186) fears (0.176) gameplay (0.168) detail (0.166) \n",
      "\n",
      "by || topped (0.201) member (0.189) featuring (0.185) independence (0.177) \n",
      "\n",
      "valkyria || released (0.178) specimen (0.161) components (0.159) government (0.149) \n",
      "\n",
      "recalled || franchise (0.210) exemplified (0.201) gaming (0.199) wanting (0.194) \n",
      "\n",
      "overturned || post (0.192) demo (0.191) target (0.184) lose (0.180) \n",
      "\n",
      "purpose || chance (0.191) always (0.186) name (0.183) ai (0.168) \n",
      "\n",
      "publicity || appearances (0.199) turn (0.188) offenders (0.162) douglas (0.161) \n",
      "\n",
      "racetrack || problems (0.192) blue (0.179) club (0.168) staff (0.157) \n",
      "\n",
      "-----------\n",
      "Epoch: 23/50\n",
      "     Train Loss: 3.2e+01\n",
      "     Valid Loss: 3.6e+01\n",
      "     Training Time (mins): 0.0\n",
      "\n",
      "\n",
      "-----------\n",
      "chronicles || elect (0.200) for (0.172) visual (0.159) creating (0.143) \n",
      "\n",
      "first || played (0.202) become (0.200) essentially (0.151) garrison (0.151) \n",
      "\n",
      "soldiers || completion (0.200) 422 (0.177) three (0.170) kotaku (0.168) \n",
      "\n",
      "release || of (0.202) newer (0.177) pacing (0.167) initially (0.146) \n",
      "\n",
      "due || play (0.185) effort (0.178) proved (0.174) found (0.171) \n",
      "\n",
      "outposts || purchase (0.179) orders (0.168) where (0.167) took (0.165) \n",
      "\n",
      "particularly || masonry (0.204) additional (0.174) seeks (0.169) appearances (0.163) \n",
      "\n",
      "pacific || recently (0.236) turns (0.176) thick (0.159) whose (0.155) \n",
      "\n",
      "parallel || possible (0.187) noting (0.171) unless (0.168) 422nd (0.167) \n",
      "\n",
      "period || transferred (0.209) next (0.165) impress (0.158) temporary (0.150) \n",
      "\n",
      "-----------\n",
      "Epoch: 24/50\n",
      "     Train Loss: 3.2e+01\n",
      "     Valid Loss: 3.5e+01\n",
      "     Training Time (mins): 0.0\n",
      "\n",
      "\n",
      "-----------\n",
      "3 || produced (0.208) effort (0.168) destroyed (0.165) provided (0.162) \n",
      "\n",
      "ii || revealed (0.215) replayed (0.181) eisenbeis (0.171) perhaps (0.163) \n",
      "\n",
      "missions || 1997 (0.161) permanent (0.150) either (0.147) deserters (0.145) \n",
      "\n",
      "who || reinforcements (0.188) were (0.178) 1894 (0.166) raven (0.166) \n",
      "\n",
      "army || atonality (0.200) flux (0.171) gradually (0.168) vision (0.158) \n",
      "\n",
      "preview || highly (0.172) 91 (0.155) motto (0.148) titled (0.146) \n",
      "\n",
      "procession || essential (0.198) media (0.186) table (0.182) sense (0.177) \n",
      "\n",
      "permitted || honjou (0.192) club (0.177) classes (0.168) if (0.148) \n",
      "\n",
      "putting || table (0.207) rivals (0.201) men (0.159) weapons (0.159) \n",
      "\n",
      "receives || several (0.180) gameplay (0.177) gallia (0.169) partially (0.163) \n",
      "\n",
      "-----------\n",
      "Epoch: 25/50\n",
      "     Train Loss: 3.2e+01\n",
      "     Valid Loss: 3.5e+01\n",
      "     Training Time (mins): 0.0\n",
      "\n",
      "\n",
      "-----------\n",
      "after || partly (0.204) spoil (0.171) as (0.164) between (0.162) \n",
      "\n",
      "ii || revealed (0.215) replayed (0.181) eisenbeis (0.171) perhaps (0.163) \n",
      "\n",
      "no || boosts (0.185) platform (0.154) post (0.151) book (0.148) \n",
      "\n",
      "into || hinting (0.182) battlefield (0.181) pleased (0.176) blue (0.168) \n",
      "\n",
      "theme || alongside (0.174) bass (0.158) pre (0.155) individuality (0.155) \n",
      "\n",
      "quickly || goes (0.174) extra (0.162) works (0.155) depot (0.153) \n",
      "\n",
      "parallel || possible (0.187) noting (0.172) 422nd (0.168) unless (0.167) \n",
      "\n",
      "operations || whose (0.165) wire (0.164) decommissioning (0.163) serve (0.160) \n",
      "\n",
      "prevent || civil (0.158) guitar (0.158) unaltered (0.147) vehicles (0.143) \n",
      "\n",
      "ready || concept (0.158) returning (0.158) writers (0.158) incursion (0.157) \n",
      "\n",
      "-----------\n",
      "Epoch: 26/50\n",
      "     Train Loss: 3.1e+01\n",
      "     Valid Loss: 3.5e+01\n",
      "     Training Time (mins): 0.0\n",
      "\n",
      "\n",
      "-----------\n",
      "release || of (0.203) newer (0.177) pacing (0.167) initially (0.146) \n",
      "\n",
      "february || it (0.212) wish (0.174) name (0.172) unless (0.168) \n",
      "\n",
      "state || scene (0.175) ordered (0.172) masonry (0.155) face (0.150) \n",
      "\n",
      "gameplay || designed (0.232) revolution (0.190) seemingly (0.180) president (0.179) \n",
      "\n",
      "as || extended (0.193) composed (0.175) after (0.164) apply (0.163) \n",
      "\n",
      "park || unaltered (0.171) aspect (0.166) intended (0.156) dvd (0.150) \n",
      "\n",
      "putting || table (0.207) rivals (0.201) men (0.159) weapons (0.159) \n",
      "\n",
      "ready || concept (0.159) returning (0.159) writers (0.158) incursion (0.157) \n",
      "\n",
      "pacific || recently (0.236) turns (0.177) thick (0.159) whose (0.155) \n",
      "\n",
      "progresses || differing (0.210) getting (0.189) central (0.185) ohta (0.180) \n",
      "\n",
      "-----------\n",
      "Epoch: 27/50\n",
      "     Train Loss: 3.1e+01\n",
      "     Valid Loss: 3.4e+01\n",
      "     Training Time (mins): 0.0\n",
      "\n",
      "\n",
      "-----------\n",
      "rock || control (0.175) totten (0.172) recalled (0.158) blurring (0.156) \n",
      "\n",
      "february || it (0.213) wish (0.175) name (0.172) unless (0.168) \n",
      "\n",
      "original || review (0.189) special (0.188) exemplified (0.172) due (0.166) \n",
      "\n",
      "an || azure (0.171) content (0.161) go (0.161) based (0.161) \n",
      "\n",
      "soldiers || completion (0.199) 422 (0.179) kotaku (0.169) three (0.168) \n",
      "\n",
      "ohta || progresses (0.180) handled (0.168) handful (0.162) him (0.159) \n",
      "\n",
      "problem || sentiment (0.163) nation (0.156) officer (0.153) maoh (0.151) \n",
      "\n",
      "nobuhiro || happens (0.180) besides (0.170) fantasy (0.167) units (0.165) \n",
      "\n",
      "offered || reveal (0.190) years (0.183) armed (0.163) versions (0.162) \n",
      "\n",
      "publicity || appearances (0.200) turn (0.188) offenders (0.163) douglas (0.161) \n",
      "\n",
      "-----------\n",
      "Epoch: 28/50\n",
      "     Train Loss: 3.1e+01\n",
      "     Valid Loss: 3.5e+01\n",
      "     Training Time (mins): 0.0\n",
      "\n",
      "\n",
      "-----------\n",
      "during || volumes (0.167) identities (0.165) referred (0.162) themselves (0.158) \n",
      "\n",
      "team || worked (0.180) kept (0.165) kondō (0.164) deserters (0.154) \n",
      "\n",
      "arkansas || 1861 (0.159) unconfirmed (0.155) world (0.152) forms (0.150) \n",
      "\n",
      "building || losses (0.224) style (0.195) love (0.179) needed (0.176) \n",
      "\n",
      "had || ammunition (0.192) save (0.152) told (0.147) telling (0.147) \n",
      "\n",
      "officers || serve (0.203) bass (0.161) octagonal (0.156) list (0.150) \n",
      "\n",
      "offered || reveal (0.190) years (0.183) armed (0.163) versions (0.162) \n",
      "\n",
      "putting || table (0.206) rivals (0.201) men (0.159) weapons (0.158) \n",
      "\n",
      "point || 13 (0.190) demo (0.181) although (0.179) hiroshi (0.169) \n",
      "\n",
      "permitted || honjou (0.192) club (0.177) classes (0.168) if (0.149) \n",
      "\n",
      "-----------\n",
      "Epoch: 29/50\n",
      "     Train Loss: 3e+01\n",
      "     Valid Loss: 3.4e+01\n",
      "     Training Time (mins): 0.0\n",
      "\n",
      "\n",
      "-----------\n",
      "governor || 4 (0.182) walker (0.181) 10 (0.165) they (0.159) \n",
      "\n",
      "valkyria || released (0.179) components (0.162) specimen (0.160) government (0.152) \n",
      "\n",
      "same || part (0.199) azure (0.185) criticized (0.184) featuring (0.176) \n",
      "\n",
      "gallian || class (0.243) full (0.186) thirty (0.169) number (0.155) \n",
      "\n",
      "february || it (0.214) wish (0.175) name (0.173) unless (0.168) \n",
      "\n",
      "polygon || tactical (0.169) left (0.163) unique (0.162) distributed (0.160) \n",
      "\n",
      "reassess || offenders (0.184) idea (0.183) raven (0.170) mostly (0.169) \n",
      "\n",
      "outskirts || koichi (0.175) purpose (0.160) character (0.158) shift (0.158) \n",
      "\n",
      "nintendo || summer (0.178) appearance (0.177) jinxed (0.176) redeem (0.165) \n",
      "\n",
      "possible || parallel (0.187) instruments (0.183) part (0.175) telegram (0.170) \n",
      "\n",
      "-----------\n",
      "Epoch: 30/50\n",
      "     Train Loss: 3e+01\n",
      "     Valid Loss: 3.4e+01\n",
      "     Training Time (mins): 0.0\n",
      "\n",
      "\n",
      "-----------\n",
      "development || ammunition (0.214) home (0.198) unique (0.196) telegram (0.183) \n",
      "\n",
      "during || volumes (0.167) identities (0.166) referred (0.163) themselves (0.158) \n",
      "\n",
      "s || g (0.206) riela (0.181) exterior (0.175) ultimate (0.167) \n",
      "\n",
      "were || entertaining (0.181) essential (0.179) who (0.178) main (0.174) \n",
      "\n",
      "was || abraham (0.188) space (0.186) duty (0.175) tgs (0.166) \n",
      "\n",
      "owing || shared (0.161) majority (0.139) adjustments (0.137) distress (0.137) \n",
      "\n",
      "realistic || goals (0.189) exclusive (0.172) create (0.165) passing (0.164) \n",
      "\n",
      "portraits || museum (0.150) 4 (0.148) war (0.146) taga (0.145) \n",
      "\n",
      "proposed || potentials (0.214) may (0.202) provisions (0.199) besides (0.189) \n",
      "\n",
      "prompted || translated (0.181) rumor (0.159) perhaps (0.158) english (0.150) \n",
      "\n",
      "-----------\n",
      "Epoch: 31/50\n",
      "     Train Loss: 2.9e+01\n",
      "     Valid Loss: 3.4e+01\n",
      "     Training Time (mins): 0.0\n",
      "\n",
      "\n",
      "-----------\n",
      "would || rector (0.180) direct (0.177) retained (0.166) but (0.160) \n",
      "\n",
      "of || throughout (0.207) release (0.204) music (0.169) settings (0.165) \n",
      "\n",
      "gallian || class (0.243) full (0.186) thirty (0.169) number (0.156) \n",
      "\n",
      "squad || received (0.170) 27 (0.158) convention (0.156) fate (0.154) \n",
      "\n",
      "arkansas || 1861 (0.160) unconfirmed (0.155) world (0.152) forms (0.150) \n",
      "\n",
      "plot || two (0.187) arms (0.169) unlocked (0.169) surrendering (0.154) \n",
      "\n",
      "pacific || recently (0.236) turns (0.177) thick (0.159) whose (0.154) \n",
      "\n",
      "promote || call (0.167) hounded (0.159) yet (0.158) 8 (0.158) \n",
      "\n",
      "playable || game (0.177) determine (0.176) allocated (0.170) iii (0.168) \n",
      "\n",
      "perceived || color (0.175) natural (0.154) also (0.150) budget (0.143) \n",
      "\n",
      "-----------\n",
      "Epoch: 32/50\n",
      "     Train Loss: 2.9e+01\n",
      "     Valid Loss: 3.3e+01\n",
      "     Training Time (mins): 0.0\n",
      "\n",
      "\n",
      "-----------\n",
      "but || ign (0.178) erased (0.173) central (0.160) would (0.160) \n",
      "\n",
      "such || divorced (0.181) assemble (0.173) review (0.169) established (0.158) \n",
      "\n",
      "story || underwent (0.198) article (0.191) title (0.171) erase (0.166) \n",
      "\n",
      "were || entertaining (0.181) essential (0.180) who (0.178) main (0.174) \n",
      "\n",
      "anime || highly (0.163) quality (0.162) kazuki (0.161) table (0.153) \n",
      "\n",
      "number || troops (0.183) interpreted (0.175) linear (0.167) necessary (0.159) \n",
      "\n",
      "ready || concept (0.159) writers (0.158) returning (0.158) incursion (0.157) \n",
      "\n",
      "pervades || employing (0.203) recorded (0.161) site (0.160) dangerous (0.158) \n",
      "\n",
      "principle || criticized (0.226) sega (0.223) people (0.172) highly (0.167) \n",
      "\n",
      "president || conway (0.208) unaltered (0.190) gameplay (0.178) removed (0.176) \n",
      "\n",
      "-----------\n",
      "Epoch: 33/50\n",
      "     Train Loss: 2.9e+01\n",
      "     Valid Loss: 3.3e+01\n",
      "     Training Time (mins): 0.0\n",
      "\n",
      "\n",
      "-----------\n",
      "due || play (0.185) effort (0.181) proved (0.173) found (0.172) \n",
      "\n",
      "playstation || composer (0.216) item (0.196) switch (0.182) shortly (0.167) \n",
      "\n",
      "s || g (0.206) riela (0.181) exterior (0.176) ultimate (0.167) \n",
      "\n",
      "than || sung (0.168) protagonists (0.158) enemies (0.156) buildings (0.155) \n",
      "\n",
      "who || reinforcements (0.189) were (0.178) raven (0.168) 1894 (0.164) \n",
      "\n",
      "person || events (0.172) property (0.161) shared (0.159) downloadable (0.156) \n",
      "\n",
      "praising || 5 (0.213) takayuki (0.179) closure (0.172) up (0.168) \n",
      "\n",
      "ordering || chosen (0.195) this (0.180) lived (0.163) make (0.159) \n",
      "\n",
      "nintendo || summer (0.179) appearance (0.178) jinxed (0.177) redeem (0.166) \n",
      "\n",
      "passage || short (0.207) stone (0.196) these (0.185) evidence (0.155) \n",
      "\n",
      "-----------\n",
      "Epoch: 34/50\n",
      "     Train Loss: 2.8e+01\n",
      "     Valid Loss: 3.4e+01\n",
      "     Training Time (mins): 0.0\n",
      "\n",
      "\n",
      "-----------\n",
      "after || partly (0.202) spoil (0.171) as (0.165) good (0.162) \n",
      "\n",
      "playstation || composer (0.216) item (0.196) switch (0.182) shortly (0.166) \n",
      "\n",
      "iii || proved (0.182) playable (0.167) price (0.164) direct (0.156) \n",
      "\n",
      "ii || revealed (0.216) replayed (0.184) eisenbeis (0.173) perhaps (0.163) \n",
      "\n",
      "squad || received (0.172) 27 (0.157) convention (0.157) fate (0.155) \n",
      "\n",
      "officers || serve (0.203) bass (0.161) octagonal (0.156) list (0.151) \n",
      "\n",
      "perceived || color (0.175) natural (0.155) also (0.150) budget (0.143) \n",
      "\n",
      "president || conway (0.208) unaltered (0.190) gameplay (0.178) removed (0.176) \n",
      "\n",
      "ramsey || january (0.189) pictures (0.184) kazuki (0.167) granted (0.164) \n",
      "\n",
      "oath || bass (0.174) revenge (0.167) worked (0.165) lit (0.156) \n",
      "\n",
      "-----------\n",
      "Epoch: 35/50\n",
      "     Train Loss: 2.8e+01\n",
      "     Valid Loss: 3.3e+01\n",
      "     Training Time (mins): 0.0\n",
      "\n",
      "\n",
      "-----------\n",
      "be || armed (0.205) fears (0.201) table (0.184) assembled (0.160) \n",
      "\n",
      "in || summer (0.170) of (0.166) maintaining (0.158) penal (0.155) \n",
      "\n",
      "was || space (0.189) abraham (0.188) duty (0.176) tgs (0.167) \n",
      "\n",
      "military || someone (0.164) lyrics (0.157) related (0.144) unmei (0.143) \n",
      "\n",
      "its || hana (0.196) permanent (0.171) left (0.171) playing (0.169) \n",
      "\n",
      "passing || asked (0.182) runs (0.174) surrender (0.168) removal (0.167) \n",
      "\n",
      "publicity || appearances (0.202) turn (0.188) offenders (0.163) douglas (0.161) \n",
      "\n",
      "proposed || potentials (0.215) may (0.203) provisions (0.199) besides (0.189) \n",
      "\n",
      "promote || call (0.166) hounded (0.159) yet (0.158) 8 (0.158) \n",
      "\n",
      "provisions || proposed (0.199) focused (0.197) extended (0.181) off (0.174) \n",
      "\n",
      "-----------\n",
      "Epoch: 36/50\n",
      "     Train Loss: 2.8e+01\n",
      "     Valid Loss: 3.3e+01\n",
      "     Training Time (mins): 0.0\n",
      "\n",
      "\n",
      "-----------\n",
      "due || play (0.184) effort (0.181) proved (0.173) found (0.172) \n",
      "\n",
      "been || vision (0.161) activate (0.157) instead (0.156) seiko (0.154) \n",
      "\n",
      "federal || evidence (0.202) my (0.190) akari (0.188) shinji (0.174) \n",
      "\n",
      "anime || highly (0.163) quality (0.162) kazuki (0.162) table (0.154) \n",
      "\n",
      "gameplay || designed (0.233) revolution (0.191) seemingly (0.179) president (0.177) \n",
      "\n",
      "recently || pacific (0.236) nintendo (0.150) delivery (0.146) although (0.144) \n",
      "\n",
      "precious || either (0.238) control (0.190) sealed (0.175) then (0.164) \n",
      "\n",
      "person || events (0.172) property (0.161) shared (0.158) downloadable (0.155) \n",
      "\n",
      "pacific || recently (0.236) turns (0.177) thick (0.159) concept (0.153) \n",
      "\n",
      "publicity || appearances (0.202) turn (0.189) offenders (0.163) douglas (0.161) \n",
      "\n",
      "-----------\n",
      "Epoch: 37/50\n",
      "     Train Loss: 2.8e+01\n",
      "     Valid Loss: 3.3e+01\n",
      "     Training Time (mins): 0.0\n",
      "\n",
      "\n",
      "-----------\n",
      "after || partly (0.202) spoil (0.172) as (0.165) good (0.163) \n",
      "\n",
      "he || safe (0.185) 10 (0.176) begin (0.170) arranged (0.159) \n",
      "\n",
      "series || birthplace (0.164) move (0.164) always (0.163) downloadable (0.155) \n",
      "\n",
      "a || militia (0.159) engine (0.155) seiko (0.153) forced (0.153) \n",
      "\n",
      "characters || art (0.185) secession (0.167) owned (0.165) played (0.164) \n",
      "\n",
      "ramsey || january (0.189) pictures (0.185) kazuki (0.167) stripped (0.164) \n",
      "\n",
      "pictures || ramsey (0.185) south (0.173) subject (0.172) speech (0.169) \n",
      "\n",
      "perspective || met (0.188) crowe (0.187) native (0.178) elements (0.168) \n",
      "\n",
      "offered || reveal (0.189) years (0.182) armed (0.165) versions (0.162) \n",
      "\n",
      "possible || parallel (0.187) instruments (0.184) part (0.175) this (0.172) \n",
      "\n",
      "-----------\n",
      "Epoch: 38/50\n",
      "     Train Loss: 2.7e+01\n",
      "     Valid Loss: 3.3e+01\n",
      "     Training Time (mins): 0.0\n",
      "\n",
      "\n",
      "-----------\n",
      "that || copy (0.193) along (0.165) richard (0.151) s (0.147) \n",
      "\n",
      "games || none (0.187) regular (0.172) g (0.167) consequences (0.162) \n",
      "\n",
      "building || losses (0.225) style (0.197) love (0.180) needed (0.178) \n",
      "\n",
      "and || fire (0.203) franchise (0.179) musical (0.163) legislature (0.160) \n",
      "\n",
      "was || space (0.191) abraham (0.188) duty (0.175) tgs (0.167) \n",
      "\n",
      "particular || became (0.190) abilities (0.188) subject (0.178) battle (0.164) \n",
      "\n",
      "plausible || unit (0.181) did (0.177) antiquities (0.166) united (0.165) \n",
      "\n",
      "nobuhiro || happens (0.181) besides (0.171) fantasy (0.167) units (0.164) \n",
      "\n",
      "number || troops (0.184) interpreted (0.175) linear (0.170) necessary (0.160) \n",
      "\n",
      "president || conway (0.208) unaltered (0.189) gameplay (0.177) removed (0.176) \n",
      "\n",
      "-----------\n",
      "Epoch: 39/50\n",
      "     Train Loss: 2.7e+01\n",
      "     Valid Loss: 3.3e+01\n",
      "     Training Time (mins): 0.0\n",
      "\n",
      "\n",
      "-----------\n",
      "be || armed (0.206) fears (0.200) table (0.184) assembled (0.161) \n",
      "\n",
      "on || creating (0.196) authorized (0.189) female (0.156) visuals (0.148) \n",
      "\n",
      "military || someone (0.164) lyrics (0.156) in (0.144) related (0.144) \n",
      "\n",
      "rock || control (0.179) totten (0.171) parts (0.159) blurring (0.159) \n",
      "\n",
      "such || divorced (0.179) assemble (0.171) review (0.170) established (0.161) \n",
      "\n",
      "offered || reveal (0.189) years (0.182) armed (0.165) versions (0.162) \n",
      "\n",
      "ohta || progresses (0.179) handled (0.170) handful (0.164) him (0.162) \n",
      "\n",
      "oklahoma || redeem (0.193) something (0.176) always (0.157) main (0.150) \n",
      "\n",
      "purchase || limited (0.191) outposts (0.179) guitar (0.176) antiquities (0.169) \n",
      "\n",
      "overturned || post (0.192) demo (0.189) target (0.183) lose (0.182) \n",
      "\n",
      "-----------\n",
      "Epoch: 40/50\n",
      "     Train Loss: 2.7e+01\n",
      "     Valid Loss: 3.2e+01\n",
      "     Training Time (mins): 0.0\n",
      "\n",
      "\n",
      "-----------\n",
      "battle || skills (0.179) seven (0.177) found (0.171) destroyed (0.167) \n",
      "\n",
      "but || ign (0.180) erased (0.173) would (0.163) central (0.160) \n",
      "\n",
      "original || review (0.190) special (0.190) exemplified (0.171) due (0.170) \n",
      "\n",
      "theme || alongside (0.172) bass (0.162) pre (0.157) individuality (0.156) \n",
      "\n",
      "not || need (0.174) patch (0.172) affected (0.168) half (0.163) \n",
      "\n",
      "president || conway (0.208) unaltered (0.189) gameplay (0.176) removed (0.176) \n",
      "\n",
      "nine || newer (0.198) escorted (0.192) robert (0.177) always (0.166) \n",
      "\n",
      "problems || racetrack (0.191) trial (0.169) house (0.155) douglas (0.148) \n",
      "\n",
      "racetrack || problems (0.191) blue (0.176) club (0.168) staff (0.157) \n",
      "\n",
      "offered || reveal (0.189) years (0.182) armed (0.166) versions (0.161) \n",
      "\n",
      "-----------\n",
      "Epoch: 41/50\n",
      "     Train Loss: 2.7e+01\n",
      "     Valid Loss: 3.3e+01\n",
      "     Training Time (mins): 0.0\n",
      "\n",
      "\n",
      "-----------\n",
      "released || detailing (0.189) built (0.183) valkyria (0.182) life (0.174) \n",
      "\n",
      "iii || proved (0.181) playable (0.167) price (0.163) direct (0.157) \n",
      "\n",
      "an || azure (0.172) based (0.166) go (0.163) content (0.163) \n",
      "\n",
      "was || space (0.193) abraham (0.188) duty (0.176) tgs (0.167) \n",
      "\n",
      "character || experience (0.180) site (0.171) saku (0.171) outskirts (0.157) \n",
      "\n",
      "oldest || include (0.200) book (0.169) second (0.155) expose (0.154) \n",
      "\n",
      "poor || did (0.173) certain (0.166) second (0.165) anonymous (0.147) \n",
      "\n",
      "quickly || goes (0.174) extra (0.163) depot (0.153) works (0.153) \n",
      "\n",
      "profound || despite (0.191) changing (0.180) multi (0.179) 422 (0.173) \n",
      "\n",
      "pre || appropriated (0.181) great (0.179) according (0.167) theme (0.157) \n",
      "\n",
      "-----------\n",
      "Epoch: 42/50\n",
      "     Train Loss: 2.6e+01\n",
      "     Valid Loss: 3.1e+01\n",
      "     Training Time (mins): 0.0\n",
      "\n",
      "\n",
      "-----------\n",
      "governor || 4 (0.183) walker (0.181) 10 (0.165) either (0.158) \n",
      "\n",
      "same || part (0.199) azure (0.185) criticized (0.185) towards (0.176) \n",
      "\n",
      "after || partly (0.201) spoil (0.174) as (0.166) good (0.165) \n",
      "\n",
      "3 || produced (0.214) destroyed (0.170) effort (0.166) provided (0.164) \n",
      "\n",
      "at || grant (0.218) response (0.205) they (0.180) very (0.168) \n",
      "\n",
      "property || calamity (0.184) person (0.161) anonymous (0.151) aspect (0.148) \n",
      "\n",
      "peace || consequence (0.178) simulation (0.169) sung (0.168) 422 (0.153) \n",
      "\n",
      "parts || vehemently (0.165) work (0.165) rock (0.159) serving (0.154) \n",
      "\n",
      "outposts || purchase (0.179) orders (0.169) took (0.167) ease (0.166) \n",
      "\n",
      "perspective || met (0.188) crowe (0.188) native (0.178) elements (0.169) \n",
      "\n",
      "-----------\n",
      "Epoch: 43/50\n",
      "     Train Loss: 2.6e+01\n",
      "     Valid Loss: 3.2e+01\n",
      "     Training Time (mins): 0.0\n",
      "\n",
      "\n",
      "-----------\n",
      "battlefield || dlc (0.194) book (0.193) into (0.181) cutscenes (0.169) \n",
      "\n",
      "team || worked (0.183) kondō (0.165) kept (0.163) deserters (0.156) \n",
      "\n",
      "for || could (0.192) chronicles (0.188) table (0.177) may (0.173) \n",
      "\n",
      "order || achieve (0.202) records (0.171) conquered (0.171) handful (0.169) \n",
      "\n",
      "3 || produced (0.214) destroyed (0.170) effort (0.166) provided (0.164) \n",
      "\n",
      "preview || highly (0.172) 91 (0.155) motto (0.147) titled (0.146) \n",
      "\n",
      "protagonists || again (0.197) expressing (0.176) moves (0.168) take (0.165) \n",
      "\n",
      "parts || vehemently (0.166) work (0.164) rock (0.159) serving (0.155) \n",
      "\n",
      "racetrack || problems (0.191) blue (0.175) club (0.168) staff (0.157) \n",
      "\n",
      "perspective || met (0.188) crowe (0.188) native (0.178) elements (0.169) \n",
      "\n",
      "-----------\n",
      "Epoch: 44/50\n",
      "     Train Loss: 2.6e+01\n",
      "     Valid Loss: 3.1e+01\n",
      "     Training Time (mins): 0.0\n",
      "\n",
      "\n",
      "-----------\n",
      "state || scene (0.174) ordered (0.172) masonry (0.155) hana (0.151) \n",
      "\n",
      "after || partly (0.202) spoil (0.174) as (0.166) good (0.164) \n",
      "\n",
      "by || topped (0.204) featuring (0.183) member (0.183) independence (0.181) \n",
      "\n",
      "of || release (0.209) throughout (0.209) in (0.175) music (0.173) \n",
      "\n",
      "for || could (0.193) chronicles (0.188) table (0.178) may (0.173) \n",
      "\n",
      "nintendo || summer (0.182) appearance (0.178) jinxed (0.176) redeem (0.166) \n",
      "\n",
      "newly || save (0.201) speech (0.196) destroys (0.185) woman (0.173) \n",
      "\n",
      "popular || ai (0.183) players (0.169) weapon (0.154) soldiers (0.152) \n",
      "\n",
      "overall || recorded (0.213) carrying (0.203) expel (0.177) criticisms (0.160) \n",
      "\n",
      "permanent || its (0.169) writers (0.168) main (0.162) title (0.159) \n",
      "\n",
      "-----------\n",
      "Epoch: 45/50\n",
      "     Train Loss: 2.6e+01\n",
      "     Valid Loss: 3.1e+01\n",
      "     Training Time (mins): 0.0\n",
      "\n",
      "\n",
      "-----------\n",
      "war || with (0.231) player (0.198) names (0.180) could (0.176) \n",
      "\n",
      "released || detailing (0.188) built (0.184) valkyria (0.182) life (0.174) \n",
      "\n",
      "little || difficulty (0.183) 27 (0.178) guitar (0.174) decommissioning (0.173) \n",
      "\n",
      "it || february (0.216) 4th (0.193) specimen (0.177) supposed (0.169) \n",
      "\n",
      "along || coming (0.186) that (0.168) used (0.160) interview (0.158) \n",
      "\n",
      "ohta || progresses (0.179) handled (0.170) handful (0.165) him (0.161) \n",
      "\n",
      "post || overturned (0.193) look (0.172) instead (0.172) where (0.162) \n",
      "\n",
      "ready || concept (0.160) returning (0.159) writers (0.159) incursion (0.158) \n",
      "\n",
      "provided || removed (0.185) wii (0.179) august (0.176) consequence (0.172) \n",
      "\n",
      "occasional || successful (0.208) closure (0.177) extra (0.160) maps (0.159) \n",
      "\n",
      "-----------\n",
      "Epoch: 46/50\n",
      "     Train Loss: 2.5e+01\n",
      "     Valid Loss: 3.2e+01\n",
      "     Training Time (mins): 0.0\n",
      "\n",
      "\n",
      "-----------\n",
      "they || large (0.195) at (0.181) research (0.174) kurt (0.159) \n",
      "\n",
      "anime || highly (0.165) kazuki (0.165) quality (0.162) table (0.152) \n",
      "\n",
      "while || compose (0.177) official (0.166) present (0.162) song (0.150) \n",
      "\n",
      "game || components (0.240) works (0.188) playable (0.187) western (0.179) \n",
      "\n",
      "through || forgiving (0.202) macarthur (0.171) 2012 (0.169) known (0.167) \n",
      "\n",
      "outposts || purchase (0.179) orders (0.169) took (0.167) ease (0.166) \n",
      "\n",
      "outskirts || koichi (0.176) purpose (0.160) character (0.158) surrender (0.157) \n",
      "\n",
      "recently || pacific (0.236) nintendo (0.150) delivery (0.146) although (0.144) \n",
      "\n",
      "profound || despite (0.192) multi (0.181) changing (0.180) 422 (0.172) \n",
      "\n",
      "putting || rivals (0.201) table (0.201) men (0.159) system (0.156) \n",
      "\n",
      "-----------\n",
      "Epoch: 47/50\n",
      "     Train Loss: 2.5e+01\n",
      "     Valid Loss: 3.2e+01\n",
      "     Training Time (mins): 0.0\n",
      "\n",
      "\n",
      "-----------\n",
      "game || components (0.240) works (0.189) playable (0.187) western (0.179) \n",
      "\n",
      "character || experience (0.180) site (0.172) saku (0.171) outskirts (0.157) \n",
      "\n",
      "he || safe (0.185) 10 (0.176) begin (0.173) arranged (0.159) \n",
      "\n",
      "not || patch (0.174) need (0.173) affected (0.166) half (0.161) \n",
      "\n",
      "same || part (0.200) azure (0.186) criticized (0.185) towards (0.176) \n",
      "\n",
      "perspective || met (0.189) crowe (0.189) native (0.178) elements (0.169) \n",
      "\n",
      "prompted || translated (0.177) rumor (0.159) perhaps (0.158) english (0.150) \n",
      "\n",
      "officers || serve (0.203) bass (0.161) octagonal (0.156) list (0.150) \n",
      "\n",
      "provisions || proposed (0.201) focused (0.198) extended (0.180) off (0.171) \n",
      "\n",
      "occurs || down (0.189) following (0.179) quality (0.178) you (0.165) \n",
      "\n",
      "-----------\n",
      "Epoch: 48/50\n",
      "     Train Loss: 2.5e+01\n",
      "     Valid Loss: 3.1e+01\n",
      "     Training Time (mins): 0.0\n",
      "\n",
      "\n",
      "-----------\n",
      "no || boosts (0.187) platform (0.153) book (0.148) command (0.148) \n",
      "\n",
      "a || militia (0.160) seiko (0.154) engine (0.153) media (0.152) \n",
      "\n",
      "nameless || dangers (0.175) once (0.168) act (0.164) to (0.162) \n",
      "\n",
      "chronicles || elect (0.197) for (0.191) visual (0.166) creating (0.152) \n",
      "\n",
      "each || visual (0.182) interpose (0.166) written (0.159) number (0.154) \n",
      "\n",
      "ohta || progresses (0.179) handled (0.170) handful (0.165) him (0.161) \n",
      "\n",
      "oldest || include (0.200) book (0.169) expose (0.155) 3ds (0.154) \n",
      "\n",
      "permitted || honjou (0.190) club (0.177) classes (0.165) if (0.148) \n",
      "\n",
      "publicity || appearances (0.203) turn (0.189) offenders (0.163) douglas (0.161) \n",
      "\n",
      "possible || parallel (0.187) instruments (0.184) part (0.178) this (0.173) \n",
      "\n",
      "-----------\n",
      "Epoch: 49/50\n",
      "     Train Loss: 2.5e+01\n",
      "     Valid Loss: 3.1e+01\n",
      "     Training Time (mins): 0.0\n",
      "\n",
      "\n",
      "-----------\n",
      "arkansas || 1861 (0.160) unconfirmed (0.158) forms (0.153) world (0.152) \n",
      "\n",
      "3 || produced (0.216) destroyed (0.171) effort (0.165) provided (0.164) \n",
      "\n",
      "development || ammunition (0.211) unique (0.198) home (0.197) telegram (0.187) \n",
      "\n",
      "february || it (0.216) wish (0.177) name (0.175) platform (0.169) \n",
      "\n",
      "soldiers || completion (0.197) 422 (0.182) map (0.172) kotaku (0.170) \n",
      "\n",
      "problems || racetrack (0.191) trial (0.169) house (0.155) douglas (0.148) \n",
      "\n",
      "purchase || limited (0.190) outposts (0.179) guitar (0.176) antiquities (0.170) \n",
      "\n",
      "post || overturned (0.193) look (0.173) instead (0.172) where (0.161) \n",
      "\n",
      "realistic || goals (0.189) exclusive (0.172) create (0.166) structure (0.165) \n",
      "\n",
      "permanent || writers (0.169) its (0.168) main (0.162) title (0.158) \n",
      "\n",
      "-----------\n",
      "Epoch: 50/50\n",
      "     Train Loss: 2.4e+01\n",
      "     Valid Loss: 3.1e+01\n",
      "     Training Time (mins): 0.0\n",
      "\n",
      "\n",
      "-----------\n",
      "war || with (0.232) player (0.200) names (0.182) could (0.178) \n",
      "\n",
      "their || removal (0.184) fears (0.182) gameplay (0.180) having (0.175) \n",
      "\n",
      "battle || skills (0.181) seven (0.181) found (0.170) destroyed (0.168) \n",
      "\n",
      "with || war (0.232) fight (0.206) time (0.205) standing (0.177) \n",
      "\n",
      "development || ammunition (0.210) unique (0.198) home (0.197) telegram (0.188) \n",
      "\n",
      "period || transferred (0.208) next (0.167) impress (0.159) temporary (0.154) \n",
      "\n",
      "principle || criticized (0.226) sega (0.221) people (0.172) highly (0.168) \n",
      "\n",
      "ready || concept (0.160) writers (0.159) returning (0.159) incursion (0.159) \n",
      "\n",
      "proved || rather (0.191) iii (0.180) due (0.174) instead (0.173) \n",
      "\n",
      "poor || did (0.172) certain (0.165) second (0.163) anonymous (0.147) \n",
      "\n",
      "-----------\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "        model=w2v,\n",
    "        params=params,\n",
    "        optimizer=optimizer,\n",
    "        train_iter=sentences[:int(0.8*len(sentences))],\n",
    "        valid_iter=sentences[int(0.8*len(sentences)):],\n",
    "        map=tmap,\n",
    "        method =batchtool\n",
    "    )\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cdffc34c-d436-433a-add4-ba701c2d67c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TokenMap check :  index('the')= 0 , index('<>') 1344 , token(10)=  game , dim(vocab)=  1345 , \n",
      "\t\t frequency('a')=  82 , frequency('<>')=  nan , frequency('.')=  nan\n",
      "BatchTool check : 0.00023020257826887662 0\n",
      "\t\t  dim(input) 18232 dim(output) 18232\n",
      "DataLoader check : \n",
      "\t 1 tensor([136, 136, 136, 136, 136,  32,  32,  32]) tensor([  7,  11,  31,  32,  48,  11,  31, 136])\n",
      "\t 2 tensor([455, 455, 455, 455, 455, 455, 349, 349]) tensor([ 72,  96,  18, 349, 151,  86,  96,  18])\n",
      "\t 3 tensor([ 15,  15,  15,  15,  15, 656, 656, 656]) tensor([ 72,  10, 656, 197, 353,   0,  10,  15])\n",
      "\t 4 tensor([67, 67, 67, 67, 67, 67, 67, 27]) tensor([921,  89, 264,  27, 111,   4, 186,  89])\n",
      "\t 5 tensor([ 84,  84,  84,  84,  84,  84,  84, 243]) tensor([1265,   12,   20,  794,  243,  495,  138,   12])\n",
      "\t 6 tensor([363, 363, 363, 363, 363, 363, 363, 895]) tensor([  9,  33, 308,  79, 895, 215, 392,  33])\n",
      "\t 7 tensor([245, 245, 245, 245, 245, 245, 245, 245]) tensor([  36,    6,  343,    3, 1194,   99,   14,    1])\n",
      "\t 8 tensor([ 7,  7,  7,  7,  7,  7, 58, 58]) tensor([ 9, 12, 52, 58,  7, 11, 12, 52])\n",
      "\t 9 tensor([  8,   8,   8,   8,   8,   8, 968, 968]) tensor([ 161,    6,  441,  968, 1016,   47,  161,    6])\n",
      "\t 10 tensor([ 0,  0,  0,  0,  0,  0,  0, 39]) tensor([  40,   33,  388,   39,   98, 1144,   14,   33])\n",
      "\t 11 tensor([ 10,  10,  10,  10, 276, 276, 276, 516]) tensor([109,  92, 276, 516,  92,  10, 516,   0])\n",
      "\t 12 tensor([1132, 1132, 1132, 1132, 1132, 1132, 1132,   19]) tensor([176, 677,   5,   0,  19, 456,  78, 677])\n",
      "\t 13 tensor([96, 96, 96, 96, 96, 96,  3,  3]) tensor([ 386,  438,    3,  601, 1041,  253,  386,  438])\n",
      "\t 14 tensor([86, 86, 86, 86, 86, 86, 86, 97]) tensor([  61,    2,   18,   66,   97, 1262,    9,   18])\n",
      "\t 15 tensor([  0,   0,   0,   0,   0,   0,   0, 140]) tensor([273,  16, 688, 140,  76, 111, 862,  16])\n",
      "\t 16 tensor([  6,   6,   6,   6, 561, 561, 561, 561]) tensor([561,  13,   0, 206,   6,  13,   0, 206])\n",
      "\t 17 tensor([ 92,  92,  92,  92,  92,  92,  92, 521]) tensor([ 18,   6, 438,  13, 521, 228, 217,   6])\n",
      "\t 18 tensor([480, 480, 480, 480, 480, 480, 407, 407]) tensor([  8,  92, 295, 407, 116, 204,  92, 295])\n",
      "\t 19 tensor([], dtype=torch.int64) tensor([], dtype=torch.int64)\n",
      "W2V check : negative sampling distribution \n",
      "\t tensor([0.0317, 0.0151, 0.0140, 0.0118, 0.0102, 0.0099], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "if _debug_ == True:\n",
    "    \n",
    "    in_ , out_ =batchtool.collate_fn(sentences)\n",
    "    dataloader = DataLoader(\n",
    "                sentences[:200],\n",
    "                batch_size=params.batch_size,\n",
    "                shuffle=False,\n",
    "                collate_fn=batchtool.collate_fn\n",
    "            )\n",
    "    dist = w2v.get_unigram_exp()\n",
    "\n",
    "        \n",
    "    print(\"TokenMap check :\",' index(\\'the\\')=', tmap.get_index('the'), ', index(\\'<>\\')', tmap.get_index('<>'), \n",
    "          ', token(10)= ', tmap.get_token(10), ', dim(vocab)= ',tmap.dim_vocab,\n",
    "          ', \\n\\t\\t frequency(\\'a\\')= ', tmap.get_frequency('a'), ', frequency(\\'<>\\')= ', tmap.get_frequency('<>'), \n",
    "          ', frequency(\\'.\\')= ', tmap.get_frequency('.'))\n",
    "    print(\"BatchTool check :\",batchtool.frequency_from_percentile(50), batchtool.get_discard_probs()[100])\n",
    "    print(f\"\\t\\t  dim(input) {len(in_)} dim(output) {len(out_)}\")\n",
    "    print(\"DataLoader check : \")\n",
    "    for i, batch in enumerate(dataloader, 1):\n",
    "        inputs = batch[0]\n",
    "        outputs = batch[1]\n",
    "        print('\\t',i, inputs[:8], outputs[:8])\n",
    "    print(\"W2V check : negative sampling distribution \\n\\t\", dist[:6])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
