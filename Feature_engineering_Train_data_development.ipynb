{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c66ce527-f5f4-4d1b-bca8-a56bf65d2725",
   "metadata": {},
   "source": [
    "# Feature engineering & Train data development <a id=''></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f621e446-ae01-4254-b20d-855b27813dbe",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "  * 1 [Import libriaries and Load data](#load_data)\n",
    "  * 2 [Training data development](#training_data)\n",
    "  * 3 [Train-test split](#train-test_split)\n",
    "  * 4 [Models](#models)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbca3538-f106-4955-a6ac-f905d6be2f8d",
   "metadata": {},
   "source": [
    "## 1 Import libraries and Load data<a id='load_data'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0368b2b7-7e3d-4334-8800-946783a108a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch version:  2.2.0\n",
      "numpy version:  1.25.2\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from itertools import permutations\n",
    "\n",
    "\n",
    "from HuffmanTree import HuffmanNode,build_huffman_tree,generate_codebook,visualize_huffman_tree\n",
    "from CategoryTree import TreeNode, build_tree, add_to_node, get_path\n",
    "\n",
    "pd.options.mode.copy_on_write = True\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "print('torch version: ', torch.__version__)\n",
    "print('numpy version: ', np.__version__)\n",
    "\n",
    "_debug_ = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d88715e-2bf9-46d7-84de-551f8ec7acc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_evt= pd.read_csv('events_df.csv')\n",
    "df_cat= pd.read_csv('category_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17371172-5341-4cb8-92fe-ec065b07e059",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_trs = df_evt[(df_evt['event'] == 'transaction') & (df_evt['categoryid']> -1)]\n",
    "df_freq = df_trs.groupby('itemid').agg(frequency = pd.NamedAgg(column='itemid', aggfunc='size'),\n",
    "                                      categoryid = pd.NamedAgg(column='categoryid',aggfunc= 'first')).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85fd398c-a4f7-4bab-9c45-dfc12cf72bc6",
   "metadata": {},
   "source": [
    "## 2 Training data development<a id='training_data'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e89ffee1-df71-4dcf-8629-04f5a77f3cd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>visitorid</th>\n",
       "      <th>event</th>\n",
       "      <th>itemid</th>\n",
       "      <th>transactionid</th>\n",
       "      <th>date</th>\n",
       "      <th>session_by_day</th>\n",
       "      <th>categoryid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>172</td>\n",
       "      <td>transaction</td>\n",
       "      <td>465522</td>\n",
       "      <td>9725</td>\n",
       "      <td>2015-08-15</td>\n",
       "      <td>3</td>\n",
       "      <td>196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>172</td>\n",
       "      <td>transaction</td>\n",
       "      <td>10034</td>\n",
       "      <td>9725</td>\n",
       "      <td>2015-08-15</td>\n",
       "      <td>3</td>\n",
       "      <td>1219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>186</td>\n",
       "      <td>transaction</td>\n",
       "      <td>49029</td>\n",
       "      <td>8726</td>\n",
       "      <td>2015-08-12</td>\n",
       "      <td>1</td>\n",
       "      <td>579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>264</td>\n",
       "      <td>transaction</td>\n",
       "      <td>161949</td>\n",
       "      <td>8445</td>\n",
       "      <td>2015-09-07</td>\n",
       "      <td>1</td>\n",
       "      <td>1421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>264</td>\n",
       "      <td>transaction</td>\n",
       "      <td>459835</td>\n",
       "      <td>8445</td>\n",
       "      <td>2015-09-07</td>\n",
       "      <td>1</td>\n",
       "      <td>1421</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     visitorid        event  itemid  transactionid        date  \\\n",
       "333        172  transaction  465522           9725  2015-08-15   \n",
       "357        172  transaction   10034           9725  2015-08-15   \n",
       "385        186  transaction   49029           8726  2015-08-12   \n",
       "495        264  transaction  161949           8445  2015-09-07   \n",
       "499        264  transaction  459835           8445  2015-09-07   \n",
       "\n",
       "     session_by_day  categoryid  \n",
       "333               3         196  \n",
       "357               3        1219  \n",
       "385               1         579  \n",
       "495               1        1421  \n",
       "499               1        1421  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_trs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb4dc5b6-ff25-4ddb-a464-d58f0b3088fb",
   "metadata": {},
   "source": [
    "**To ensure efficient training and simplicity, only sessions with multiple items (>1) involved in transactions are selected. In reality, context-target item pairs are not always symmetric, and the order matters in purchasing related items; for example, a laptop is often bought before a charger. Therefore, it would be more accurate to model single items as well in future.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "824b99f4-eb7a-4eec-9168-0db653aa26f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "visitorid         13027\n",
      "session_by_day    13027\n",
      "items             13027\n",
      "dtype: int64\n",
      "visitorid         3055\n",
      "session_by_day    3055\n",
      "items             3055\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df_items = df_trs.groupby(['visitorid','session_by_day']).agg(items = pd.NamedAgg(column='itemid', aggfunc=list)).reset_index()\n",
    "print(df_items.count())\n",
    "\n",
    "df_filtered = df_items[df_items['items'].apply(len) > 1]\n",
    "print(df_filtered.count())\n",
    "\n",
    "items = df_filtered['items'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bab4a61-ced6-4903-8424-8fd251c94541",
   "metadata": {},
   "source": [
    "**Next, all possible order-sensitive item-item pairs are constructed from the items present in a given session.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a24fd1d-d2dd-459c-bcf7-66e28d4a4bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = []\n",
    "outputs = []\n",
    "for items_in_session in items:\n",
    "    pairs = list(permutations(items_in_session, 2))\n",
    "    for pair in pairs:\n",
    "        target_id, context_id = pair[0],pair[1]\n",
    "        inputs.append([target_id])\n",
    "        outputs.append(context_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed5e004-8a04-4570-a591-058ddef69ccb",
   "metadata": {},
   "source": [
    "## 3 Train-test split<a id='train-test_split'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "94121fb0-c1c1-461f-a6f3-53dd8f78419e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to torch.tensor\n",
    "X = torch.tensor(inputs, dtype=torch.long)\n",
    "y = torch.tensor(outputs, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "031d000b-609d-44df-a864-664d18343058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[465522],\n",
      "        [ 10034],\n",
      "        [161949],\n",
      "        [459835],\n",
      "        [393144],\n",
      "        [445559],\n",
      "        [342086],\n",
      "        [346661],\n",
      "        [ 19278],\n",
      "        [353548]])\n",
      "tensor([ 10034, 465522, 459835, 161949, 445559, 393144, 346661, 342086, 353548,\n",
      "         19278])\n"
     ]
    }
   ],
   "source": [
    "print(X[:10])\n",
    "print(y[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b64389ae-515a-4b69-8d11-4d6a3c7624fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split using train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Wrap in TensorDataset\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "val_dataset = TensorDataset(X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcacee17-bd8d-47f6-86a9-bb6f2dc6c3aa",
   "metadata": {},
   "source": [
    "## 4 Models<a id='models'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b990133-4079-4cfd-9bde-6c12583fe9af",
   "metadata": {},
   "source": [
    "This project explores various recommender system models, with the Hierarchical Item2Vec model as the main focus. The model and supporting utility functions are imported from the corresponding source files.\n",
    "\n",
    "- **ItemMap.py** : contains category, item and frequency and methods to fetch index and item/category  (TokenMap ~ ItemMap -> HuffmanTree) \n",
    "- **HierarchicalItem2Vec.py** : main model and trainer, the model reduces to Item2Vec when Params.lambda_cat is set to zero.\n",
    "- **parameters.py**\n",
    "- batch_tool.py : this method is still being called, but it is obsolete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9007f7f3-8cd2-4980-a707-2dd1d5d7862b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from parameters import Params\n",
    "from ItemMap import ItemMap\n",
    "from HierarchicalItem2Vec import HierarchicalItem2Vec, Trainer\n",
    "from batch_tool import BatchToolItem # this is obsolete as of Sep 25, 2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f81e3d9c-f5ca-4417-bc7d-b7cfbe8c520d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_category_tree(rootcode_, df_, itemmap_):\n",
    "    tree_cat = TreeNode(rootcode_) \n",
    "    build_tree(0,{root_code:tree_cat}, df_) \n",
    "    for catid, itemid in itemmap_.items():\n",
    "        for itemidx in itemid.keys():\n",
    "            add_to_node(tree_cat,catid,itemidx) \n",
    "    return tree_cat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cce31885-8bef-4a9f-bf5e-50400a7ec579",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of inner nodes : 11644\n"
     ]
    }
   ],
   "source": [
    "# Huffman Tree\n",
    "begin_index = 500000\n",
    "imap = ItemMap(df_freq, df_cat)\n",
    "itemmap = imap.dict_items\n",
    "flat_itemmap = imap.flat_items\n",
    "total_inner_nodes, huff_tree = build_huffman_tree(begin_index, None, flat_itemmap, None)\n",
    "print(f'Total number of inner nodes : {total_inner_nodes}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dd3fbd6d-95ca-48dc-8cf3-47f3293d202f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Category Tree\n",
    "root_code = 10000\n",
    "cat_tree =  build_category_tree(root_code, df_cat, itemmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "15651756-79eb-4b60-9085-beb21be2147f",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = Params()\n",
    "params.model_name = 'HierarchicalItem2Vec'\n",
    "params.model_dir = \"weights/{}\".format(params.model_name)\n",
    "params.n_epochs = 1 # 1 for test\n",
    "os.makedirs(params.model_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2e32bbad-2f9d-451c-83d0-16120f14a488",
   "metadata": {},
   "outputs": [],
   "source": [
    "batchtool = BatchToolItem(imap, params)\n",
    "hi2v = HierarchicalItem2Vec(imap, params, huff_tree, cat_tree)\n",
    "optimizer = torch.optim.Adam(params = hi2v.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cef539a9-0ba2-48f0-9476-d6f4f89bcc22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------\n",
      "304558 || 318941 (0.216) 184320 (0.199) 400161 (0.196) 201850 (0.193) \n",
      "\n",
      "295196 || 387780 (0.202) 66621 (0.201) 458046 (0.185) 110720 (0.184) \n",
      "\n",
      "247225 || 317435 (0.190) 456656 (0.190) 146325 (0.189) 221833 (0.188) \n",
      "\n",
      "85876 || 294419 (0.204) 318941 (0.197) 59850 (0.194) 222772 (0.190) \n",
      "\n",
      "259292 || 172470 (0.210) 145503 (0.210) 396053 (0.208) 47447 (0.208) \n",
      "\n",
      "305901 || 329097 (0.208) 255622 (0.199) 448600 (0.198) 425359 (0.191) \n",
      "\n",
      "48184 || 125831 (0.213) 448548 (0.198) 328005 (0.187) 58752 (0.187) \n",
      "\n",
      "277362 || 62290 (0.207) 83952 (0.193) 233313 (0.191) 210002 (0.187) \n",
      "\n",
      "379671 || 374759 (0.200) 11976 (0.196) 242521 (0.195) 388333 (0.187) \n",
      "\n",
      "255933 || 295184 (0.206) 304685 (0.199) 26835 (0.196) 455010 (0.189) \n",
      "\n",
      "-----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 6300/6300 [03:41<00:00, 28.39it/s, loss=0.974]\n",
      "Epoch 1/1: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 1575/1575 [00:31<00:00, 49.38it/s, loss=0.883]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/1\n",
      "     Train Loss: 0.95\n",
      "     Valid Loss: 0.9\n",
      "     Training Time (mins): 3.7\n",
      "\n",
      "\n",
      "-----------\n",
      "356740 || 65941 (0.231) 456748 (0.205) 172108 (0.201) 40058 (0.198) \n",
      "\n",
      "464286 || 412416 (0.224) 417008 (0.207) 253549 (0.204) 144507 (0.196) \n",
      "\n",
      "57301 || 22772 (0.198) 148338 (0.197) 120822 (0.194) 69730 (0.194) \n",
      "\n",
      "10864 || 37197 (0.224) 30314 (0.222) 417300 (0.206) 193908 (0.204) \n",
      "\n",
      "407460 || 18724 (0.207) 310620 (0.205) 350372 (0.198) 422905 (0.187) \n",
      "\n",
      "458140 || 313269 (0.215) 317417 (0.200) 95834 (0.193) 296933 (0.192) \n",
      "\n",
      "276324 || 114514 (0.203) 130451 (0.201) 190774 (0.201) 330506 (0.190) \n",
      "\n",
      "241061 || 307201 (0.226) 42328 (0.207) 314801 (0.201) 96069 (0.192) \n",
      "\n",
      "210237 || 249027 (0.225) 139725 (0.202) 435709 (0.195) 268881 (0.194) \n",
      "\n",
      "418744 || 410669 (0.224) 133404 (0.214) 20098 (0.202) 458946 (0.197) \n",
      "\n",
      "-----------\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "        model=hi2v,\n",
    "        params=params,\n",
    "        optimizer=optimizer,\n",
    "        train_iter=train_dataset,\n",
    "        valid_iter=val_dataset,\n",
    "        map=imap,\n",
    "        method =batchtool\n",
    "    )\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2371cdd-625d-4abd-a269-9dc7dede9f56",
   "metadata": {},
   "source": [
    "Testing was performed on 10 randomly selected items to identify the 5 closest items before and after training. At this stage, we run only one epoch to verify that the model executes correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d1d80d95-e9ea-499b-897c-682e90bc6e38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ItemMap check :  index(322295)= 2963 , dim(items)=  11645\n",
      "DataLoader check : \n",
      "\t 1 [203368, 339975, 110077] tensor([465522, 369773, 276013]) tensor([3582, 9683, 8937]) tensor([11516,  6822,  8123])\n",
      "\t 2 [320130, 246683, 464954] tensor([ 29196, 214617, 452802]) tensor([11633,  1045,  4414]) tensor([11616, 10188,  2933])\n",
      "\t 3 [191733, 424421, 449220] tensor([ 94773, 249702, 336405]) tensor([10255, 11227,  9420]) tensor([8352,  336, 9405])\n",
      "\t 4 [242819, 456056, 119972] tensor([ 89247, 287871, 159042]) tensor([ 8502, 11566,  9407]) tensor([10077,  6746,  3904])\n",
      "\t 5 [352541, 437457, 94344] tensor([154977,   5675, 229577]) tensor([10721,  4735,  4467]) tensor([ 3199, 11090,  1563])\n",
      "\t 6 [119736, 213334, 191050] tensor([220066, 206970, 185241]) tensor([11643,  1561,  7903]) tensor([11219,  8051,  9565])\n",
      "tensor([-1.2592,  0.1417, -1.4469,  1.7868,  0.8740, -0.1168,  0.8048, -0.2106,\n",
      "        -0.3699,  0.2181], grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "source": [
    "if _debug_ == True:\n",
    "    \n",
    "    dataloader = DataLoader(\n",
    "                train_dataset,\n",
    "                batch_size=params.batch_size,\n",
    "                shuffle=True,\n",
    "                #collate_fn=batchtool.collate_fn\n",
    "            )\n",
    "\n",
    "    print(\"ItemMap check :\",' index(322295)=', imap.get_item_index(322295), ', dim(items)= ',imap.dim_items)\n",
    "    print(\"DataLoader check : \")\n",
    "    for i, batch in enumerate(dataloader, 1):\n",
    "        inputs = batch[0]\n",
    "        outputs = batch[1]\n",
    "        flat_inputs = torch.flatten(inputs).tolist()\n",
    "        input_indices = imap.get_item_index(flat_inputs)\n",
    "        torch_input = torch.tensor(input_indices)\n",
    "        output_indices = imap.get_item_index(torch.tensor(outputs).tolist())\n",
    "        torch_output = torch.tensor(output_indices)\n",
    "        print('\\t',i, flat_inputs[:3], outputs[:3], torch_input[:3], torch_output[:3])\n",
    "        if i>5:\n",
    "            break\n",
    "\n",
    "    item_embeddings = nn.Embedding(\n",
    "            imap.dim_items, \n",
    "            params.dim_embedding\n",
    "        )\n",
    "    target_embs = item_embeddings(torch_input) \n",
    "    print(target_embs[0,:10])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
