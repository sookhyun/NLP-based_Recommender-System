{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3642aa41-1dc1-487a-88f2-f3e930778f49",
   "metadata": {},
   "source": [
    "# Modelling <a id=''></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a09f2ff4-d87f-4513-a9e1-de0191a06307",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "  * 1 [Import libriaries and Load data](#load_data)\n",
    "  * 2 [Prepare data](#prepare_data)\n",
    "  * 3 [Overview of recommender systems](#overview)\n",
    "    * 3.1 [Two primary approaches](#approaches)\n",
    "    * 3.2 [Deep learning-based recommender systems](#DL_rec_systems)\n",
    "  * 4 [Modelling](#modelling)\n",
    "    * 4.1 [Item2Vec and hierarchical Item2Vec models](#item2vec)\n",
    "    * 4.2 [Hyperparameters](#hyperparameters)\n",
    "  * 5 [Evaluation](#evaluation)\n",
    "  * 6 [Conclusion](#conclusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa50d1d0-2333-486f-809e-9cc577ecea58",
   "metadata": {},
   "source": [
    "## 1 Import libraries and Load data<a id='load_data'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "091ffc2a-7e7c-4719-bf1d-671969baa47b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch version:  2.2.0\n",
      "numpy version:  1.25.2\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from itertools import permutations, chain\n",
    "\n",
    "from HuffmanTree import HuffmanNode,build_huffman_tree,generate_codebook,visualize_huffman_tree\n",
    "from CategoryTree import TreeNode, build_tree, add_to_node, build_category_tree, get_path\n",
    "from parameters import Params\n",
    "from ItemMap import ItemMap\n",
    "from HierarchicalItem2Vec import HierarchicalItem2Vec, Trainer\n",
    "from batch_tool import BatchToolItem # this is obsolete as of Sep 25, 2025\n",
    "\n",
    "pd.options.mode.copy_on_write = True\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "print('torch version: ', torch.__version__)\n",
    "print('numpy version: ', np.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3b717f2-b341-4986-99c0-835140b689fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_evt= pd.read_csv('events_df.csv')\n",
    "df_cat= pd.read_csv('category_df.csv')\n",
    "\n",
    "df_trs = df_evt[(df_evt['event'] == 'transaction') & (df_evt['categoryid']> -1)]\n",
    "df_freq = df_trs.groupby('itemid').agg(frequency = pd.NamedAgg(column='itemid', aggfunc='size'),\n",
    "                                      categoryid = pd.NamedAgg(column='categoryid',aggfunc= 'first')).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ef436a-adbe-419a-85d3-952aecae2555",
   "metadata": {},
   "source": [
    "## 2 Prepare data<a id='prepare_data'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a95b90b-75ca-4834-aa90-76607634a385",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "visitorid         13027\n",
      "session_by_day    13027\n",
      "items             13027\n",
      "dtype: int64\n",
      "visitorid         3055\n",
      "session_by_day    3055\n",
      "items             3055\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df_items = df_trs.groupby(['visitorid','session_by_day']).agg(items = pd.NamedAgg(column='itemid', aggfunc=list)).reset_index()\n",
    "print(df_items.count())\n",
    "\n",
    "df_filtered = df_items[df_items['items'].apply(len) > 1]\n",
    "print(df_filtered.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "388dad56-5b39-4d7b-8aaa-3000d51b43aa",
   "metadata": {},
   "source": [
    "**In order to optimize model performance, we perform pruning on the data. Low frequency or unused data can negatively affect the performance indirectly through shared internal nodes in the Huffman tree.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17552961-efc3-40e2-81c8-04fe417cf387",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "itemid        11645\n",
      "frequency     11645\n",
      "categoryid    11645\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "itemid        7547\n",
       "frequency     7547\n",
       "categoryid    7547\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items = df_filtered['items'].tolist()\n",
    "\n",
    "flat = list(chain.from_iterable(items))\n",
    "set_items = set(flat)\n",
    "\n",
    "print(df_freq.count())\n",
    "df_freq = df_freq.loc[df_freq['itemid'].isin(set_items)]\n",
    "df_freq.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fdfa144d-72bb-48bf-9b8e-5907f3a423d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_items = [461686,119736,213834,7943,312728] # highest frequency items\n",
    "do_test = True\n",
    "\n",
    "inputs = []\n",
    "outputs = []\n",
    "for items_in_session in items:\n",
    "    \n",
    "    pairs = list(permutations(items_in_session, 2))\n",
    "    for pair in pairs:\n",
    "        target_id, context_id = pair[0],pair[1]\n",
    "        if target_id not in test_items and context_id not in test_items and do_test:\n",
    "            continue\n",
    "        inputs.append([target_id])\n",
    "        outputs.append(context_id)\n",
    "        \n",
    "# Convert to torch.tensor\n",
    "X = torch.tensor(inputs, dtype=torch.long)\n",
    "y = torch.tensor(outputs, dtype=torch.long)\n",
    "\n",
    "# Split using train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Wrap in TensorDataset\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "val_dataset = TensorDataset(X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bbd5f43-3578-44d9-b4f0-c0ea4ec2a30f",
   "metadata": {},
   "source": [
    "## 3 Overview of Recommender Systems<a id='overview'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9caacacb-d4ea-457d-ae40-30a5db8ea0c1",
   "metadata": {},
   "source": [
    "### 3.1 Two primary approaches<a id='approaches'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a21cfddd-09bb-488e-b3c0-c26c5b3e7b5d",
   "metadata": {},
   "source": [
    "*Recommender systems* suggest items to users based on their preferences, behavior, or similarities with others. They're widely used in platforms like Netflix, Amazon, Spotify, and YouTube. The primary goal is to predict a user’s preferences and recommend items they are likely to engage with such as movies, products, news articles, or even people. There are mainly two core types of recommender systems, **collaborative filtering** and **content-based filtering**. \n",
    "\n",
    "**Collaborative filtering** can be further divided into:\n",
    "* *User-based filtering*, which identifies users with similar preferences and recommends items those users have liked.\n",
    "* *Item-based filtering*, which finds items similar to those the user has previously liked and recommends them.\n",
    "\n",
    "Similarity between users or items is typically computed using distance or similarity measures such as *Euclidean distance, Pearson correlation*, or *cosine similarity*. It's important to note that in collaborative filtering, item similarity is not based on the inherent features of the items, but rather on user interaction patterns. Item-based collaborative filtering is particularly effective in systems where the number of users significantly exceeds the number of items. \n",
    "However, collaborative filtering has several limitations:\n",
    "\n",
    "- Data sparsity: User-item interaction matrices are often sparse, making it difficult to identify meaningful patterns.\n",
    "- Cold start: The system struggles to make recommendations for new users or new items due to a lack of interaction data.\n",
    "- Scalability: Performance can degrade as the number of users or items grows.\n",
    "- Popularity bias: Tends to over-recommend popular items, reducing personalization and diversity.\n",
    "- Lack of Interpretability: Recommendations are based on patterns in user behavior, not explicit item attributes.\n",
    "- Gray sheep problem: Users with unique or atypical preferences may receive poor recommendations.\n",
    "\n",
    "**Content-based filtering**, on the other hand, recommends items that are similar to those a user has liked in the past. These similarities are determined based on item attributes or features, such as categories, tags, genres, or other metadata. This approach can help address some of the limitations of collaborative filtering.\n",
    "\n",
    "- No Need for Other Users' Data: Recommendations are based solely on the user’s own preferences and item features.\n",
    "- Handles Cold Start (User Side): Can recommend items to new users after only a few interactions.\n",
    "- Interpretable Recommendations.\n",
    "- Less prone to recommending only popular items.\n",
    "- Privacy-Friendly: Doesn’t require analyzing other users’ data.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c181355d-6104-4f6f-b1ca-5293756285e5",
   "metadata": {},
   "source": [
    "### 3.2 Deep learning-based recommender systems<a id='DL_rec_systems'></a>   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14e3d09-90ac-4ebd-996e-19f4012aca35",
   "metadata": {},
   "source": [
    "\n",
    "In recent years, deep learning-based recommender systems have gained prominence due to their superior performance and ability to model complex user-item interactions.\n",
    "\n",
    "- Better at Capturing Non-Linear and Complex Patterns\n",
    "- Better at Cold Start and Sparse Data\n",
    "- Effective Feature Representation (Embeddings): can automatically learn *dense, low-dimensional representations (embeddings)* of users and items from sparse interaction data\n",
    "- Integration of Multiple Data Types (Multimodal Inputs)\n",
    "- Personalized and Context-Aware Recommendations: Deep models can learn user-specific behaviors, preferences, and temporal patterns.\n",
    "\n",
    "different methods\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67552792-e123-4b2b-a09b-5aecdfda8355",
   "metadata": {},
   "source": [
    "## 4 Modelling <a id='modelling'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e949c0d-52b0-404f-ae2f-f55fa301aba1",
   "metadata": {},
   "source": [
    "### 4.1 Item2Vec and hierarchical Item2Vec models<a id='item2vec'></a>   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e966eda-b0b7-4d4a-9170-3b9382dc88c1",
   "metadata": {},
   "source": [
    "This project focuses on the Item2Vec model, which is based on the Word2Vec architecture originally developed for learning optimized word embeddings in natural language processing (NLP). By drawing an analogy between sequences of words and sequences of user-item interactions, Item2Vec learns dense vector representations of items that capture similarity and co-occurrence patterns. This results in more effective recommendations through meaningful item embeddings.\n",
    "\n",
    "Item2Vec is an item-based collaborative filtering technique and, as such, inherits some of the limitations discussed in the previous section, such as cold-start problems and a lack of content awareness. To address these issues, we explore a hybrid approach called Hierarchical Item2Vec, which integrates hierarchical content-based information into the embedding process. This method helps mitigate the shortcomings of purely collaborative approaches by incorporating category-level knowledge.\n",
    "\n",
    "Next, we will explore and fine-tune the model architecture and its components."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a4f7b6f-b124-41ef-b2dc-fa610cc18c1a",
   "metadata": {},
   "source": [
    "### 4.2 Hyperparameters<a id='hyperparameters'></a>  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7925877d-f39b-442d-af9d-f38bf7107a62",
   "metadata": {},
   "source": [
    "To optimize model performance, we consider the following **hyperparameters**:\n",
    "\n",
    "\n",
    "* $\\lambda_{cat}$ = {0, 0.1, 1.0, 10}\n",
    "* Embedding dimension = {32,64, 96, 128}\n",
    "* Threshold for item frequency\n",
    "* Learning rate = {0.005, 0.01, 0.05}\n",
    "* Loss function = {Negative sampling, Hierarchical softmax}\n",
    "* Similarity measure: cosine similarity, distance\n",
    "\n",
    "| Cosine Similarity Score | Interpretation                                          |\n",
    "| ----------------------- | ------------------------------------------------------- |\n",
    "| **> 0.8**               | Very high similarity (strong recommendation candidates) |\n",
    "| **0.6 – 0.8**           | High similarity (related items, likely of interest)     |\n",
    "| **0.4 – 0.6**           | Moderate similarity (some shared context)               |\n",
    "| **< 0.4**               | Low or weak similarity                                  |\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1089afaa-598f-4f7f-8a78-b481be542f17",
   "metadata": {},
   "source": [
    "#### 4.2.1 Regularization parameter $\\lambda_{cat}$<a id='lambda_cat'></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b0d0223-42c0-4e7c-ba52-0f0f6b0e47dd",
   "metadata": {},
   "source": [
    "The value of $\\lambda_{cat}$ regulates the strength of alignment between item embeddings and their respective category embeddings.\n",
    "\n",
    "We will select the following values during hyperparameter tuning:: $\\lambda_{cat}$ = {0, 0.1, 1, 10}\n",
    "\n",
    "| $\\lambda_{\\text{cat}}$ Value                 | Meaning / Effect                                                                 | When to Use                                                           |\n",
    "| -------------------------------------------- | -------------------------------------------------------------------------------- | --------------------------------------------------------------------- |\n",
    "| **0**                                        | No category alignment at all. Equivalent to Item2Vec.            | Baseline comparison; when category data is noisy or not useful.       |\n",
    "| **1 $\\times 10^{-4}$ to 1 $\\times 10^{-3}$** | Very weak alignment. Minor influence from category embeddings.                   | Categories are somewhat useful, but item-level patterns dominate.     |\n",
    "| **1 $\\times 10^{-2}$ to 0.1**              | Moderate alignment. Balanced influence between item behavior and category info.  | Often a good starting point for tuning; works well in many scenarios. |\n",
    "| **0.1 to 1.0**                           | Strong alignment. Item embeddings are pulled significantly toward category ones. | When categories are well-defined and strongly predictive.             |\n",
    "| **>1.0**                                   | Very strong alignment. Item embeddings may lose individuality.                   | Only use if category structure is known to be highly reliable.        |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc09605-06b7-4a94-9692-7b2a75de69c3",
   "metadata": {},
   "source": [
    "#### 4.2.2 Embedding dimension <a id='dim_embedding'></a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ca9c959-2b4b-427a-b9a6-61c08bbc7b55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of items  7547  total number of categories  1670\n",
      "Total number of inner nodes : 7546\n"
     ]
    }
   ],
   "source": [
    "# Huffman Tree\n",
    "begin_index = 500000\n",
    "imap = ItemMap(df_freq, df_cat)\n",
    "itemmap = imap.dict_items\n",
    "flat_itemmap = imap.flat_items\n",
    "total_inner_nodes, huff_tree = build_huffman_tree(begin_index, None, flat_itemmap, None)\n",
    "print(f'Total number of inner nodes : {total_inner_nodes}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95d1ae57-5142-4712-9fd5-674e9267328c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Category Tree\n",
    "root_code = 10000\n",
    "cat_tree =  build_category_tree(root_code, df_cat, itemmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b05a2aca-4c55-4060-9b21-105675a8258e",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = Params()\n",
    "params.model_name = 'HierarchicalItem2Vec'\n",
    "params.model_dir = \"weights/{}\".format(params.model_name)\n",
    "params.dim_embedding = 60\n",
    "params.lambda_cat = 0.2\n",
    "params.batch_size = 2\n",
    "params.n_epochs = 10 # 1 for test\n",
    "os.makedirs(params.model_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a476f97-e00e-4ba7-860d-a384d9fad7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "batchtool = BatchToolItem(imap, params)\n",
    "hi2v = HierarchicalItem2Vec(imap, params, huff_tree, cat_tree)\n",
    "optimizer = torch.optim.Adam(params = hi2v.parameters(), lr=0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3104bdb7-3ffc-47cd-a10a-092646b9251d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------\n",
      "461686 || 398756 (0.438) 427472 (0.415) 206995 (0.415) 27412 (0.408) \n",
      "\n",
      "119736 || 314952 (0.478) 86844 (0.464) 98498 (0.453) 204494 (0.440) \n",
      "\n",
      "213834 || 209125 (0.490) 496 (0.433) 354345 (0.417) 118551 (0.405) \n",
      "\n",
      "7943 || 77991 (0.452) 289298 (0.445) 98708 (0.422) 375450 (0.414) \n",
      "\n",
      "312728 || 79714 (0.450) 6047 (0.411) 337162 (0.409) 412865 (0.408) \n",
      "\n",
      "-----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 1282/1282 [00:11<00:00, 114.54it/s, loss=0.857]\n",
      "Epoch 1/10: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 321/321 [00:01<00:00, 264.64it/s, loss=0.884]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10\n",
      "     Train Loss: 0.74\n",
      "     Valid Loss: 0.68\n",
      "     Training Time (mins): 0.2\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 1282/1282 [00:12<00:00, 106.52it/s, loss=0.55]\n",
      "Epoch 2/10: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 321/321 [00:01<00:00, 217.99it/s, loss=0.472]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2/10\n",
      "     Train Loss: 0.44\n",
      "     Valid Loss: 0.68\n",
      "     Training Time (mins): 0.2\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 1282/1282 [00:11<00:00, 107.70it/s, loss=0.357]\n",
      "Epoch 3/10: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 321/321 [00:01<00:00, 223.33it/s, loss=0.432]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3/10\n",
      "     Train Loss: 0.39\n",
      "     Valid Loss: 0.69\n",
      "     Training Time (mins): 0.2\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████| 1282/1282 [00:12<00:00, 104.53it/s, loss=0.0859]\n",
      "Epoch 4/10: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 321/321 [00:01<00:00, 173.35it/s, loss=0.345]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4/10\n",
      "     Train Loss: 0.37\n",
      "     Valid Loss: 0.68\n",
      "     Training Time (mins): 0.2\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 1282/1282 [00:12<00:00, 106.39it/s, loss=0.341]\n",
      "Epoch 5/10: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 321/321 [00:01<00:00, 210.05it/s, loss=0.384]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5/10\n",
      "     Train Loss: 0.35\n",
      "     Valid Loss: 0.69\n",
      "     Training Time (mins): 0.2\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 1282/1282 [00:11<00:00, 107.91it/s, loss=0.225]\n",
      "Epoch 6/10: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 321/321 [00:01<00:00, 230.79it/s, loss=0.381]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6/10\n",
      "     Train Loss: 0.34\n",
      "     Valid Loss: 0.69\n",
      "     Training Time (mins): 0.2\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████| 1282/1282 [00:11<00:00, 107.52it/s, loss=0.0342]\n",
      "Epoch 7/10: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 321/321 [00:01<00:00, 223.83it/s, loss=0.459]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7/10\n",
      "     Train Loss: 0.33\n",
      "     Valid Loss: 0.71\n",
      "     Training Time (mins): 0.2\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 1282/1282 [00:12<00:00, 104.26it/s, loss=0.46]\n",
      "Epoch 8/10: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 321/321 [00:01<00:00, 203.80it/s, loss=0.347]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8/10\n",
      "     Train Loss: 0.33\n",
      "     Valid Loss: 0.71\n",
      "     Training Time (mins): 0.2\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 1282/1282 [00:11<00:00, 108.25it/s, loss=0.333]\n",
      "Epoch 9/10: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 321/321 [00:01<00:00, 214.47it/s, loss=0.365]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9/10\n",
      "     Train Loss: 0.33\n",
      "     Valid Loss: 0.72\n",
      "     Training Time (mins): 0.2\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████| 1282/1282 [00:11<00:00, 108.07it/s, loss=0.396]\n",
      "Epoch 10/10: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 321/321 [00:01<00:00, 222.30it/s, loss=0.295]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10/10\n",
      "     Train Loss: 0.32\n",
      "     Valid Loss: 0.72\n",
      "     Training Time (mins): 0.2\n",
      "\n",
      "\n",
      "-----------\n",
      "461686 || 65215 (0.900) 422376 (0.895) 67423 (0.893) 124081 (0.885) \n",
      "\n",
      "119736 || 186702 (0.912) 210137 (0.892) 400077 (0.891) 151178 (0.881) \n",
      "\n",
      "213834 || 277833 (0.866) 130865 (0.862) 346892 (0.859) 345373 (0.856) \n",
      "\n",
      "7943 || 318333 (0.733) 163689 (0.557) 318697 (0.546) 147879 (0.535) \n",
      "\n",
      "312728 || 63899 (0.847) 46232 (0.817) 455763 (0.765) 217548 (0.763) \n",
      "\n",
      "-----------\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "        model=hi2v,\n",
    "        params=params,\n",
    "        optimizer=optimizer,\n",
    "        train_iter=train_dataset,\n",
    "        valid_iter=val_dataset,\n",
    "        map=imap,\n",
    "        method =batchtool,\n",
    "        debug = 0\n",
    "    )\n",
    "trainer.test_tokens = [461686,119736,213834,7943,312728]\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcfd805b-61ee-4199-a385-b9e0a4f8040a",
   "metadata": {},
   "source": [
    "## 4 Evaluation <a id='evaluation'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5085d33-4e9e-41bc-8e3a-87a018aa0a0b",
   "metadata": {},
   "source": [
    "Test item groups: high-frequency, moderate-frequency items, cold items.\n",
    "For problems at hand, ranking-based evaluation metrics such as Precision@k, Recall@k, NDCG, MAP are most appropriate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf57ba8-ee5e-4f64-b163-7c9a46eeb758",
   "metadata": {},
   "source": [
    "* Precision at K\n",
    "* Recall at K"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
